{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER:** For viewing purposes only; this notebook will not run without SFUSD data in '../data/'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Packages and plot settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import models_pytorch as mp\n",
    "import data_processing as dp\n",
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import weightedtau, entropy\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import ast\n",
    "import copy\n",
    "import importlib\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='whitegrid', rc={'grid.alpha': 0.25, 'text.usetex': False})\n",
    "palette = sns.color_palette('Greys', n_colors=1) + sns.color_palette(n_colors=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years for train & test\n",
    "TRAIN_YEAR = '1718'\n",
    "TEST_YEAR = '1819'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where Avg Color Index and greatschools data lives:\n",
    "TRAIN_SCHOOL_ATTS_PATH = '../Cleaned Data/schools_rehauled_'+TRAIN_YEAR+'.csv'\n",
    "TEST_SCHOOL_ATTS_PATH = '../Cleaned Data/schools_rehauled_'+TEST_YEAR+'.csv'\n",
    "\n",
    "# Where bus route and PTA data lives:\n",
    "DETAILED_SCHOOL_ATTS_PATH = '../Cleaned Data/SFUSD School Characteristics - School Data.csv'\n",
    "\n",
    "# Where program data lives:\n",
    "TRAIN_PROGRAM_ATTS_PATH = '../Cleaned Data/programs_'+TRAIN_YEAR+'.csv'\n",
    "TEST_PROGRAM_ATTS_PATH = '../Cleaned Data/programs_'+TEST_YEAR+'.csv'\n",
    "\n",
    "# Students x schools individual travel times\n",
    "DISTANCES_PATH = '../Cleaned Data/distances.csv' # (n_students, n_schools)\n",
    "\n",
    "# Relevant choice data\n",
    "STUDENT_DATA_TRAIN = '../Cleaned Data/student_'+TRAIN_YEAR+'.csv'\n",
    "STUDENT_DATA_TEST = '../Cleaned Data/student_'+TEST_YEAR+'.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load school attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PTA fund, bus-route, before- and after-school program data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_school_attributes = pd.read_csv(DETAILED_SCHOOL_ATTS_PATH, index_col=\"School Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_school_attributes['PTA_Funds_Per_Pupil'] = [float(re.sub(r'[^\\d.]', '', amount)) for amount in detailed_school_attributes['Annual PTA funds per pupil']]\n",
    "detailed_school_attributes['School bus from'] = detailed_school_attributes['School bus from'].fillna('[]')\n",
    "detailed_school_attributes['School bus from K'] = detailed_school_attributes['School bus from']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual fixes and entries\n",
    "detailed_school_attributes.loc[796, 'School bus from K'] = '94110, 94124, 94134'\n",
    "detailed_school_attributes.loc[479, 'School bus from K'] = '94102, 94115, 94124'\n",
    "detailed_school_attributes.loc[876, 'Has Before School Programs'] = 'No'\n",
    "detailed_school_attributes.loc[876, 'Has After School Programs'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_school_attributes['School bus from K'] = detailed_school_attributes['School bus from K'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average color data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_attributes_train = pd.read_csv(TRAIN_SCHOOL_ATTS_PATH, index_col='school_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in ['ela_color', 'math_color', 'chronic_color', 'suspension_color']:\n",
    "    school_attributes_train[column].replace(['Red', 'Orange', 'Yellow', 'Green', 'Blue'], [1.,2.,3.,4.,5.], inplace=True)\n",
    "school_attributes_train['AvgColorIndex'] = school_attributes_train[['ela_color', 'math_color', 'chronic_color', 'suspension_color']].mean(numeric_only=True, axis=1)\n",
    "school_attributes_train['% FRL 2019-2022'] = detailed_school_attributes.loc[school_attributes_train.index,'% FRL']\n",
    "school_attributes_train['PTA funds per pupil'] = detailed_school_attributes.loc[school_attributes_train.index,'PTA_Funds_Per_Pupil']\n",
    "school_attributes_train['has_before_school_progs'] = detailed_school_attributes.loc[school_attributes_train.index,'Has Before School Programs'].map({'Yes':1, 'No':0})\n",
    "school_attributes_train['has_after_school_progs'] = detailed_school_attributes.loc[school_attributes_train.index,'Has After School Programs'].map({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program specific data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prog_to_nest = {'GE': 'General Education', 'MM': 'Special Education','MS': 'Special Education',\n",
    "                'SA': 'Special Education', 'AF': 'Special Education', 'ED': 'Special Education', \n",
    "                'DA': 'Special Education', 'DT': 'Special Education', 'SN': 'Spanish Language',\n",
    "                'SE': 'Spanish Language', 'NS': 'Spanish Language', 'SB': 'Spanish Language',\n",
    "                'CE': 'Chinese Language', 'CN': 'Chinese Language', 'ME': 'Chinese Language',\n",
    "                'MN': 'Chinese Language', 'CT': 'Chinese Language', 'NC': 'Chinese Language',\n",
    "                'CB': 'Chinese Language', 'JN': 'Japanese Language', 'JB': 'Japanese Language',\n",
    "                'JE': 'Japanese Language', 'KE': 'Korean Language', 'KN': 'Korean Language',\n",
    "                'FB': 'Filipino Language'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_attributes_train = pd.read_csv(TRAIN_PROGRAM_ATTS_PATH, index_col='program_id')\n",
    "program_attributes_train['school_id'] = program_attributes_train.school_id.astype(int)\n",
    "program_attributes_train['nest_membership'] = [prog_to_nest[program_type] for program_type in program_attributes_train['program_type']]\n",
    "program_attributes_train['AvgColorIndex'] = [school_attributes_train.loc[school,'AvgColorIndex'] for school in program_attributes_train.school_id]\n",
    "program_attributes_train['greatschools_rating'] = [school_attributes_train.loc[school,'greatschools_rating'] for school in program_attributes_train.school_id]\n",
    "program_attributes_train['portion_FRL'] = [school_attributes_train.loc[school,'% FRL 2019-2022']/100. for school in program_attributes_train.school_id]\n",
    "program_attributes_train['has_before_school_progs'] = [school_attributes_train.loc[school,'has_before_school_progs'] for school in program_attributes_train.school_id]\n",
    "program_attributes_train['has_after_school_progs'] = [school_attributes_train.loc[school,'has_after_school_progs'] for school in program_attributes_train.school_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=pd.Categorical(program_attributes_train['nest_membership'])\n",
    "nests = list(cat.categories)\n",
    "program_attributes_train['nest_id'] = cat.codes\n",
    "program_attributes_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load travel data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student-school sqrt. distances (miles):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pd.read_csv(DISTANCES_PATH,index_col=0)\n",
    "distances.columns = distances.columns.astype(int)\n",
    "sqrt_distances = np.sqrt(distances)\n",
    "program_distances = distances.loc[distances.index, program_attributes_train.school_id]\n",
    "program_sqrt_distances = sqrt_distances.loc[distances.index, program_attributes_train.school_id]\n",
    "program_distances.columns = program_attributes_train.index\n",
    "program_sqrt_distances.columns = program_attributes_train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper dict for language-related covariate later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_program = {'CC-Chinese Cantonese': ['CB','CE','CN','CT', 'NC'],\n",
    "                   'SP-Spanish': ['SB','SE','SN','NS'],\n",
    "                   'CM-Chinese Mandarin': ['ME','MN'],\n",
    "                   'JA-Japanese': ['JE','JN'],\n",
    "                   'KO-Korean': ['KE','KN'],\n",
    "                   'FT-Filipino Tagalog': ['FB'],\n",
    "                   'FI-Filipino Ilocano': ['FB']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_to_language = {item: k for k, v in lang_to_program.items() for item in v}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load preference data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping reported ethnicity to EdData racial categories: \n",
    "https://www.ed-data.org/article/Ethnic-Diversity-Index#:~:text=Diversity%20Index%20calculated%3F-,What%20is%20the%20Ethnic%20Diversity%20Index%3F,groups%20in%20its%20student%20population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_ethnicities(row):\n",
    "    if row['resolved_ethnicity'] in ['Decline to State']:\n",
    "        return 'Decline to State'\n",
    "    elif row['resolved_ethnicity'] in ['Black or African American']:\n",
    "        return 'Black or African American'\n",
    "    elif row['resolved_ethnicity'] in ['American Indian or Alaskan Native']:\n",
    "        return 'American Indian or Alaskan Native'\n",
    "    elif row['resolved_ethnicity'] in ['Asian', 'Asian Indian', 'Chinese', 'Korean', 'Vietnamese', 'Cambodian', 'Japanese', 'Other Asian']:\n",
    "        return 'Asian'\n",
    "    elif row['resolved_ethnicity'] in ['Hispanic/Latino']:\n",
    "        return 'Hispanic/Latino'\n",
    "    elif row['resolved_ethnicity'] in ['Filipino']:\n",
    "        return 'Filipino'\n",
    "    elif row['resolved_ethnicity'] in ['Pacific Islander', 'Other Pacific Islander', 'Samoan']:\n",
    "        return 'Pacific Islander'\n",
    "    elif row['resolved_ethnicity'] in ['White', 'Middle Eastern/Arabic']:\n",
    "        return 'White'\n",
    "    elif row['resolved_ethnicity'] in ['Two or More Races']:\n",
    "        return 'Two or More Races'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test ranking data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(STUDENT_DATA_TRAIN).assign(year=TRAIN_YEAR)\n",
    "data2 = pd.read_csv(STUDENT_DATA_TEST).assign(year=TEST_YEAR)\n",
    "raw_data = pd.concat([data1, data2], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data[raw_data.grade=='KG'].dropna(subset=['studentno'])\n",
    "df['first_participated_round'] = (~df[['r1_programs', 'r2_programs', 'r3_programs', 'r5_programs']].isna()).apply(lambda x: np.where(x)[0][0]+1, axis=1)\n",
    "df['first_participated_round'] = [roundd if roundd!= 4 else 5 for roundd in df['first_participated_round']]                                      \n",
    "for col in ['r1_ranked_idschool', 'r2_ranked_idschool', 'r3_ranked_idschool', 'r5_ranked_idschool',\n",
    "            'r1_programs', 'r2_programs', 'r3_programs', 'r5_programs',\n",
    "            'r1_listed_ranks', 'r2_listed_ranks', 'r3_listed_ranks', 'r5_listed_ranks',\n",
    "            'sibling', 'aaprek', 'aa']:\n",
    "    df[col] = df[col].fillna(value='[]').apply(lambda x: ast.literal_eval(x))\n",
    "df['idschoolattendance'] = df['idschoolattendance'].apply(lambda x: None if np.isnan(x) else int(x))\n",
    "df['freelunch_prob_group'] = pd.qcut(df['freelunch_prob'],\n",
    "                                q=[0, 1/2, 1],\n",
    "                                labels=['low', 'high']) \n",
    "df['r1_ranked_programs'] = [[str(school)+'-'+str(program)+'-KG' for school, program in zip(ranked_list, programs)] for ranked_list, programs in zip(df['r1_ranked_idschool'], df['r1_programs'])]\n",
    "df['r2_ranked_programs'] = [[str(school)+'-'+str(program)+'-KG' for school, program in zip(ranked_list, programs)] for ranked_list, programs in zip(df['r2_ranked_idschool'], df['r2_programs'])]\n",
    "df['r3_ranked_programs'] = [[str(school)+'-'+str(program)+'-KG' for school, program in zip(ranked_list, programs)] for ranked_list, programs in zip(df['r3_ranked_idschool'], df['r3_programs'])]\n",
    "df['r5_ranked_programs'] = [[str(school)+'-'+str(program)+'-KG' for school, program in zip(ranked_list, programs)] for ranked_list, programs in zip(df['r5_ranked_idschool'], df['r5_programs'])]\n",
    "df['first_ranked_programs'] = [row['r'+str(row['first_participated_round'])+'_ranked_programs'] for _, row in df.iterrows()]\n",
    "df['normed_ethnicity'] = df.apply(aggregate_ethnicities, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Repeated selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert rankings to individual choices via repeated selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dff = df[(df.year==TRAIN_YEAR)] # &(df.first_participated_round==1)]\n",
    "dataset = dp.clean_dataframe(dff, program_attributes_train, program_sqrt_distances)\n",
    "choices, student_codex, program_codex, school_codex, program_to_school, program_type_codex, program_to_program_type, ctip_codex, ballot = dp.prep_dataset(dataset, program_attributes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_programs = len(program_codex)\n",
    "num_students = len(student_codex)\n",
    "print('No. students: ', num_students)\n",
    "print('No. offerings: ', num_programs)\n",
    "print('No. schools: ', len(school_codex))\n",
    "print('No. programs: ', len(program_type_codex))\n",
    "print('Avg. len of ranking', dataset.num_ranked.mean())\n",
    "print('No. training examples', choices[0].shape[0])\n",
    "print('% CTIP1', ctip_codex.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $d$ matrices of size $(n,m)$ of $d$ individual covariates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busroutes_lookup = pd.DataFrame(0, index = df.zipcode.unique(), columns=program_sqrt_distances.columns)\n",
    "for program in program_attributes_train.index:\n",
    "    school = program_attributes_train.loc[program, 'school_id']\n",
    "    zip_list = detailed_school_attributes.loc[school, 'School bus from K']\n",
    "    busroutes_lookup.loc[zip_list, program] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busroutes = pd.DataFrame(0, columns=program_sqrt_distances.columns, index=program_sqrt_distances.index)\n",
    "siblings = pd.DataFrame(0, columns=program_sqrt_distances.columns, index=program_sqrt_distances.index)\n",
    "aaprek = pd.DataFrame(0, columns=program_sqrt_distances.columns, index=program_sqrt_distances.index)\n",
    "aa = pd.DataFrame(0, columns=program_sqrt_distances.columns, index=program_sqrt_distances.index)\n",
    "langprograms = pd.DataFrame(0, columns=program_sqrt_distances.columns, index=program_sqrt_distances.index)\n",
    "for i, row in df.iterrows():\n",
    "    student = row['studentno']\n",
    "    if student not in program_sqrt_distances.index:\n",
    "        continue\n",
    "    zipcode = row.loc['zipcode']\n",
    "    lang = row.loc['homelang_desc']\n",
    "    bg = row.loc['census_blockgroup']\n",
    "    sibling_list = row.loc['sibling']\n",
    "    prek = row.loc['aaprek']\n",
    "    aa_school = row.loc['idschoolattendance']\n",
    "    busroutes.loc[student, :] = busroutes_lookup.loc[zipcode,:]\n",
    "\n",
    "    program_series = program_attributes_train[program_attributes_train.school_id==aa_school].index\n",
    "    aa.loc[student, program_series] += 1\n",
    "\n",
    "    program_series = program_attributes_train[program_attributes_train.school_id.isin(prek)].index\n",
    "    aaprek.loc[student, program_series] += 1\n",
    "\n",
    "    program_series = program_attributes_train[program_attributes_train.school_id.isin(sibling_list)].index\n",
    "    siblings.loc[student, program_series] += 1\n",
    "\n",
    "    if (lang in ['CC-Chinese Cantonese', 'SP-Spanish', 'CM-Chinese Mandarin', 'JA-Japanese', 'KO-Korean', 'FT-Filipino Tagalog', 'FI-Filipino Ilocano']):\n",
    "        program_series = program_attributes_train[program_attributes_train.program_type.isin(lang_to_program[lang])].index\n",
    "        langprograms.loc[student, program_series] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to stack $d$ covariate matrices into single $(n,m,d)$ ndarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_covariate_matrix(program_attributes, student_codex, program_codex, ctip_codex):\n",
    "    n=len(student_codex)\n",
    "    m=len(program_codex)\n",
    "    \n",
    "    # School/program atts\n",
    "    avg_color = np.array(program_attributes.loc[program_codex, 'AvgColorIndex']).reshape(1,m) #, (n,1))[:,:,None]\n",
    "    before_after_school = np.array(program_attributes.loc[program_codex, 'has_after_school_progs']|program_attributes.loc[program_codex, 'has_before_school_progs']).reshape(1,m)\n",
    "    frl = np.array(program_attributes.loc[program_codex, 'portion_FRL']).reshape(1,m)\n",
    "\n",
    "    # Student/program atts\n",
    "    avg_color_nonCTIP = np.multiply((~ctip_codex)[:,None], avg_color)[:,:,None]\n",
    "    avg_color_CTIP = np.multiply((ctip_codex)[:,None], avg_color)[:,:,None]\n",
    "    frl_nonCTIP = np.multiply((~ctip_codex)[:,None], frl)[:,:,None]\n",
    "    frl_CTIP = np.multiply((ctip_codex)[:,None], frl)[:,:,None]\n",
    "    beforeafter_nonCTIP = np.multiply((~ctip_codex)[:,None], before_after_school)[:,:,None]\n",
    "    beforeafter_CTIP = np.multiply((ctip_codex)[:,None], before_after_school)[:,:,None]\n",
    "    \n",
    "    distances_program = np.array(program_distances.loc[student_codex, program_codex])[:,:,None]\n",
    "    within_half_mile = distances_program<0.5\n",
    "    sqrt_distances_program = np.array(program_sqrt_distances.loc[student_codex, program_codex])[:,:,None]\n",
    "    sqrt_distances_program_CTIP = np.multiply((ctip_codex)[:,None, None], sqrt_distances_program)\n",
    "    sqrt_distances_program_nonCTIP = np.multiply((~ctip_codex)[:,None, None], sqrt_distances_program)\n",
    "    \n",
    "    bus_route = np.array(busroutes.loc[student_codex, program_codex])[:,:,None]\n",
    "    sibling_match = np.array(siblings.loc[student_codex, program_codex])[:,:,None]\n",
    "    aaprek_match = np.array(aaprek.loc[student_codex, program_codex])[:,:,None]\n",
    "    aa_match = np.array(aa.loc[student_codex, program_codex])[:,:,None]\n",
    "    language_match = np.array(langprograms.loc[student_codex, program_codex])[:,:,None]\n",
    "    \n",
    "    return np.dstack([avg_color_nonCTIP,\n",
    "                      avg_color_CTIP,\n",
    "                      frl_nonCTIP,\n",
    "                      frl_CTIP,\n",
    "                      beforeafter_nonCTIP,\n",
    "                      beforeafter_CTIP,\n",
    "                      distances_program,\n",
    "                      sqrt_distances_program,\n",
    "                      sqrt_distances_program_CTIP,\n",
    "                      sqrt_distances_program_nonCTIP,\n",
    "                      within_half_mile,\n",
    "                      # within_15min_walk,\n",
    "                      bus_route,\n",
    "                      sibling_match,\n",
    "                      language_match,\n",
    "                      aa_match,\n",
    "                      aaprek_match]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_names = ['Avg. Color, non-CTIP', 'Avg. Color, CTIP', \n",
    "                   'FRL, non-CTIP', 'FRL, CTIP', \n",
    "                   'Before/after school prog, non-CTIP', 'Before/after school prog, CTIP',\n",
    "                   'Distance', 'Sqrt. distance', \n",
    "                   'Sqrt. distance, CTIP', 'Sqrt. distance, non-CTIP', \n",
    "                   'Within 0.5 mile', 'Exists bus route', \n",
    "                   'Sib. match', 'Lang. match',\n",
    "                   'AA match', 'PreK/TK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Figure 6 & 7: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_null_loss(x, x_extra, y, num_ranks=5):\n",
    "    batch_size, seq_len, _ = x.size()\n",
    "    y_hat = F.log_softmax(t.zeros((batch_size, seq_len, 1)), 1)\n",
    "    terms = []\n",
    "    for i in range(num_ranks):\n",
    "        rows = x_extra[:,2]==i\n",
    "        terms.append(F.nll_loss(y_hat[rows], y[rows, None].long()).detach().numpy())\n",
    "    return (F.nll_loss(y_hat, y[:, None].long()), terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-fold cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds=5\n",
    "shuffled = dataset.sample(frac=1).reset_index(drop=True)\n",
    "folds = np.array_split(shuffled, kfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Figure 6a: Sweep over local regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scanning $\\lambda$ over $[1e-5,1e-4,1e-3,1e-2,1e-1,1.0]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reg_sweep(i, wd, model_name, fixed_effect, linear, context):\n",
    "    result=[]\n",
    "    val = folds[i]\n",
    "    train = pd.concat([df for j, df in enumerate(folds) if j!=i])\n",
    "    \n",
    "    train_choices, train_st_codex, train_prog_codex, train_school_codex, train_program_to_school, train_program_type_codex, train_program_to_type, train_ctip_codex, train_ballot = dp.prep_dataset(train, program_attributes_train)\n",
    "    (xval, xlval, yval), val_st_codex, val_ctip_codex = dp.prep_valset(val, program_attributes_train, train_prog_codex)\n",
    "\n",
    "    X_train = generate_covariate_matrix(program_attributes_train, train_st_codex, train_prog_codex, train_ctip_codex)\n",
    "    X_val = generate_covariate_matrix(program_attributes_train, val_st_codex, train_prog_codex, val_ctip_codex)\n",
    "\n",
    "    '''\n",
    "    Train and validate models\n",
    "    '''\n",
    "    if model_name=='nested':\n",
    "        nest_memberships = program_attributes_train.loc[train_prog_codex,'nest_id'].values\n",
    "        kwargs={'item_to_school': train_program_to_school,\n",
    "                'item_to_program': train_program_to_type,\n",
    "                'covariates': X_train,\n",
    "                'num_nests': len(nests),\n",
    "                'nest_memberships': nest_memberships}\n",
    "        model, tr_loss, num_epochs, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                            num_items=len(train_prog_codex), \n",
    "                                                            epochs=1000, \n",
    "                                                            lr=1e-4 if (wd==1e-1) else 1e-5 if (wd==1e-2) else 1e-3, \n",
    "                                                            wd=wd, \n",
    "                                                            verbose=True, \n",
    "                                                            Model=sp.NestedMNL,\n",
    "                                                            **kwargs)\n",
    "        no_params = sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])    \n",
    "        result.append([model_name, i, wd, 'train', tr_loss, num_epochs, no_params])\n",
    "        yval_hat = model.forward(xval, xlval, X_val)\n",
    "        v_loss, v_loss_terms = model.loss_func(yval_hat, yval, xlval, train=False)\n",
    "        result.append([model_name, i, wd, 'val', v_loss, num_epochs, no_params])\n",
    "        return result    \n",
    "    else:\n",
    "        kwargs={'fixed_effects': fixed_effect,\n",
    "                'item_to_school': train_program_to_school,\n",
    "                'item_to_program': train_program_to_type,\n",
    "                'linear_terms': linear,\n",
    "                'covariates': X_train,\n",
    "                'context': context,\n",
    "                'k': 1}\n",
    "        model, tr_loss, num_epochs, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                            num_items=len(train_prog_codex), \n",
    "                                                            epochs=1000, \n",
    "                                                            lr=1e-3, \n",
    "                                                            wd=wd, \n",
    "                                                            verbose=True, \n",
    "                                                            **kwargs)\n",
    "        no_params = sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "        result.append([model_name, i, wd, 'train', tr_loss, num_epochs, no_params])\n",
    "        yval_hat = model.forward(xval, xlval, X_val)\n",
    "        v_loss, v_loss_terms = model.loss_func(yval_hat, yval, xlval, train=False)\n",
    "        result.append([model_name, i, wd, 'val', v_loss, num_epochs, no_params])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wds=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0]\n",
    "model_names = ['fixed', 'linear', 'cdm', 'nested']\n",
    "fixed_effects = [True, True, True, True]\n",
    "linears = [False, True, True, True]\n",
    "contexts = [False, False, True, False]\n",
    "wd_results = Parallel(n_jobs=-4)(delayed(reg_sweep)(i, wd, model_name, fe, linear, context) \n",
    "                                 for i in range(kfolds) \n",
    "                                 for wd in wds \n",
    "                                 for model_name, fe, linear, context in zip(model_names, \n",
    "                                                                            fixed_effects, \n",
    "                                                                            linears, \n",
    "                                                                            contexts))\n",
    "wd_results = [subitem for item in wd_results for subitem in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wd_results = pd.DataFrame(wd_results, columns=['model', \n",
    "                                               'fold', \n",
    "                                               'weight decay', \n",
    "                                               'loss type', \n",
    "                                               'loss', \n",
    "                                               'num epochs', \n",
    "                                               'no params'])\n",
    "wd_results['loss'] = wd_results['loss'].astype(float)\n",
    "wd_results['weight decay'] = wd_results['weight decay'].astype(float)\n",
    "wd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(data=wd_results[wd_results['loss type']=='val'], values='loss', index='model', columns='weight decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_lines = [Line2D([0], [0], color=palette[1], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[1], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[2], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[2], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[4], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[4], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[3], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[3], linestyle='-', marker='o', lw=2)]\n",
    "custom_labels = ['fixed, train', \n",
    "                 'fixed, val', \n",
    "                 'linear, train', \n",
    "                 'linear, val', \n",
    "                 'nested, train', \n",
    "                 'nested, val', \n",
    "                 'CDM, train', \n",
    "                 'CDM, val', ]\n",
    "fig=plt.figure()\n",
    "sns.lineplot(data=wd_results, x='weight decay', y='loss', hue='model', \n",
    "             style='loss type', style_order=['val', 'train'], marker='o')\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r'Local regularization, $\\lambda$')\n",
    "plt.ylabel(r'NLL')\n",
    "plt.legend(custom_lines, custom_labels, loc='lower right')\n",
    "fig.savefig('../Figs/local_reg.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Figure 6b: CDM rank sweep over embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scanning $r$ over $[2,...,10]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_sweep(i, dim):\n",
    "    result=[]\n",
    "    val = folds[i]\n",
    "    train = pd.concat([df for j, df in enumerate(folds) if j!=i])\n",
    "    \n",
    "    train_choices, train_st_codex, train_prog_codex, train_school_codex, train_program_to_school, train_program_type_codex, train_program_to_type, train_ctip_codex, train_ballot = dp.prep_dataset(train, program_attributes_train)\n",
    "    (xval, xlval, yval), val_st_codex, val_ctip_codex = dp.prep_valset(val, program_attributes_train, train_prog_codex)\n",
    "\n",
    "    '''\n",
    "    Train and validate models\n",
    "    '''\n",
    "    X_train = generate_covariate_matrix(program_attributes_train, train_st_codex, train_prog_codex, train_ctip_codex)\n",
    "    X_val = generate_covariate_matrix(program_attributes_train, val_st_codex, train_prog_codex, val_ctip_codex)\n",
    "    kwargs={'fixed_effects': True,\n",
    "            'item_to_school': train_program_to_school,\n",
    "            'item_to_program': train_program_to_type,\n",
    "            'linear_terms': True,\n",
    "            'covariates': X_train,\n",
    "            'context': True,\n",
    "            'embedding_dim': dim,\n",
    "            'k': 1}\n",
    "    model, tr_loss, num_epochs, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                        num_items=len(train_prog_codex), \n",
    "                                                        epochs=1000, \n",
    "                                                        lr=1e-3, \n",
    "                                                        wd=1e-5, \n",
    "                                                        verbose=True, \n",
    "                                                        **kwargs)\n",
    "    no_params = sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "    result.append([i, dim, 'train', tr_loss, num_epochs, no_params])\n",
    "    yval_hat = model.forward(xval, xlval, X_val)\n",
    "    v_loss, v_loss_terms = model.loss_func(yval_hat, yval, xlval)\n",
    "    result.append([i, dim, 'val', v_loss, num_epochs, no_params])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdm_results = Parallel(n_jobs=-4)(delayed(rank_sweep)(i, dim) for i in range(kfolds) for dim in range(2,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdm_results = [subitem for item in cdm_results for subitem in item]\n",
    "cdm_results = pd.DataFrame(cdm_results, columns=['fold', 'embedding dim', 'loss type', 'loss', 'num epochs', 'no params'])\n",
    "cdm_results['loss'] = cdm_results['loss'].astype(float)\n",
    "cdm_results['embedding dim'] = cdm_results['embedding dim'].astype(int)\n",
    "cdm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdm_results.pivot_table(index='embedding dim', columns='loss type', values='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_lines = [Line2D([0], [0], color=palette[3], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[3], linestyle='-', marker='o', lw=2)]\n",
    "custom_labels = ['CDM, train', \n",
    "                 'CDM, val', ]\n",
    "fig=plt.figure()\n",
    "sns.lineplot(data=cdm_results, x='embedding dim', y='loss', style='loss type', \n",
    "             style_order = ['val', 'train'], color=sns.color_palette()[2])\n",
    "plt.xlabel(r'CDM embedding dimension, $r$')\n",
    "plt.ylabel(r'NLL')\n",
    "plt.legend(custom_lines, custom_labels)\n",
    "fig.savefig('../Figs/cdm_rank.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Figure 7: Stratification hyperparameter sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scanning $k$ over $[2,...,10]$ and $\\lambda_\\mathcal{L}$ over $[0.0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_sweep(i, k, lambda_reg, lr, model_name, fixed_effect, linear, context):\n",
    "    result=[]\n",
    "    val = folds[i]\n",
    "    train = pd.concat([df for j, df in enumerate(folds) if j!=i])\n",
    "\n",
    "    train_choices, train_st_codex, train_prog_codex, train_school_codex, train_program_to_school, train_program_type_codex, train_program_to_type, train_ctip_codex, train_ballot = dp.prep_dataset(train, program_attributes_train)\n",
    "    (xval, xlval, yval), val_st_codex, val_ctip_codex = dp.prep_valset(val, program_attributes_train, train_prog_codex)\n",
    "\n",
    "    X_train = generate_covariate_matrix(program_attributes_train, train_st_codex, train_prog_codex, train_ctip_codex)\n",
    "    X_val = generate_covariate_matrix(program_attributes_train, val_st_codex, train_prog_codex, val_ctip_codex)\n",
    "    \n",
    "    if model_name == 'nested':\n",
    "        nest_memberships = program_attributes_train.loc[train_prog_codex,'nest_id'].values\n",
    "        kwargs={'item_to_school': train_program_to_school,\n",
    "                'item_to_program': train_program_to_type,\n",
    "                'covariates': X_train,\n",
    "                'num_nests': len(nests),\n",
    "                'nest_memberships': nest_memberships,\n",
    "                'k': k,\n",
    "                'lambda_reg': lambda_reg}\n",
    "        model, tr_loss, num_epochs, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                            num_items=len(train_prog_codex), \n",
    "                                                            epochs=1000, \n",
    "                                                            lr=lr, \n",
    "                                                            wd=1e-5, \n",
    "                                                            verbose=False, \n",
    "                                                            Model=sp.NestedMNL,\n",
    "                                                            **kwargs)\n",
    "        no_params = sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "        task_loss = tr_loss - np.array(tr_losses)[-1, -1]\n",
    "        result.append([model_name, i, k, lambda_reg, lr, 'train', task_loss, num_epochs, no_params])\n",
    "        result.append([model_name, i, k, lambda_reg, lr, 'train + reg', tr_loss, num_epochs, no_params])\n",
    "        yval_hat = model.forward(xval, xlval, X_val)\n",
    "        v_loss, v_loss_terms = model.loss_func(yval_hat, yval, xlval, train=False)\n",
    "        result.append([model_name, i, k, lambda_reg, lr, 'val', v_loss, num_epochs, no_params])\n",
    "        return result\n",
    "    else:\n",
    "        kwargs={'fixed_effects': fixed_effect,\n",
    "                'item_to_school': train_program_to_school,\n",
    "                'item_to_program': train_program_to_type,\n",
    "                'linear_terms': linear,\n",
    "                'covariates': X_train,\n",
    "                'context': context,\n",
    "                'embedding_dim': 10,\n",
    "                'k': k,\n",
    "                'lambda_reg': lambda_reg}\n",
    "        model, tr_loss, num_epochs, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                            num_items=len(train_prog_codex), \n",
    "                                                            epochs=1000, \n",
    "                                                            lr=lr, \n",
    "                                                            wd=1e-5, \n",
    "                                                            verbose=False, \n",
    "                                                            **kwargs)\n",
    "        no_params = sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "        task_loss = tr_loss - np.array(tr_losses)[-1, -1]\n",
    "        result.append([model_name, i, k, lambda_reg, lr, 'train', task_loss, num_epochs, no_params])\n",
    "        result.append([model_name, i, k, lambda_reg, lr, 'train + reg', tr_loss, num_epochs, no_params])\n",
    "        yval_hat = model.forward(xval, xlval, X_val)\n",
    "        v_loss, v_loss_terms = model.loss_func(yval_hat, yval, xlval, train=False)\n",
    "        result.append([model_name, i, k, lambda_reg, lr, 'val', v_loss, num_epochs, no_params])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambdas = [0.0, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1.]\n",
    "lrs = [1e-3, 1e-3, 1e-3, 1e-3, 5e-4, 5e-4, 5e-4]\n",
    "model_names = ['fixed', 'linear', 'cdm', 'nested']\n",
    "fixed_effects = [True, True, True, True]\n",
    "linears = [False, True, True, True]\n",
    "contexts = [False, False, True, False]\n",
    "\n",
    "strat_results = Parallel(n_jobs=20)(delayed(strat_sweep)(i, k, lambda_reg, lr, model_name, fe, linear, context) \n",
    "                                    for i in range(kfolds) \n",
    "                                    for k in range(2,11) \n",
    "                                    for (lambda_reg, lr) in zip(lambdas, lrs)\n",
    "                                    for model_name, fe, linear, context in zip(model_names, \n",
    "                                                                               fixed_effects, \n",
    "                                                                               linears, \n",
    "                                                                               contexts))\n",
    "strat_results = [item for sublist in strat_results for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strat_results_df = pd.DataFrame(strat_results, columns=['model', 'fold', 'k', 'lambda', 'lr', 'loss type', 'loss', 'num epochs', 'no params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results2 = Parallel(n_jobs=-4)(delayed(strat_sweep)(i, 1, 0.0, 1e-3, model_name, fe, linear, context) \n",
    "                               for i in range(kfolds) \n",
    "                               for model_name, fe, linear, context in zip(model_names, \n",
    "                                                                          fixed_effects, \n",
    "                                                                          linears, \n",
    "                                                                          contexts))\n",
    "results2 = [item for sublist in results2 for item in sublist]\n",
    "results2_df = pd.DataFrame(results2, columns=['model','fold', 'k', 'lambda', 'lr', 'loss type', 'loss', 'num epochs', 'no params'])\n",
    "strat_results_df = pd.concat([strat_results_df, results2_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pl = strat_results_df[strat_results_df['model']=='fixed']\n",
    "df_linear = strat_results_df[strat_results_df['model']=='linear']\n",
    "df_cdm = strat_results_df[strat_results_df['model']=='cdm']\n",
    "df_nested = strat_results_df[strat_results_df['model']=='nested']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pl['loss']=df_pl.loss.astype(float)\n",
    "df_linear['loss']=df_linear.loss.astype(float)\n",
    "df_cdm['loss']=df_cdm.loss.astype(float)\n",
    "df_nested['loss']=df_nested.loss.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_palette = sns.light_palette(sns.color_palette()[0], as_cmap=True)\n",
    "linear_palette = sns.light_palette(sns.color_palette()[1], as_cmap=True)\n",
    "cdm_palette = sns.light_palette(sns.color_palette()[2], as_cmap=True)\n",
    "nested_palette = sns.light_palette(sns.color_palette()[3], as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,4,figsize=(22, 10), sharex=True, sharey=True)\n",
    "\n",
    "pt_pl = pd.pivot_table(df_pl[df_pl['loss type']=='train'], values='loss', index='k', columns='lambda')\n",
    "pt_linear = pd.pivot_table(df_linear[df_linear['loss type']=='train'], values='loss', index='k', columns='lambda')\n",
    "pt_cdm = pd.pivot_table(df_cdm[df_cdm['loss type']=='train'], values='loss', index='k', columns='lambda')\n",
    "pt_nested = pd.pivot_table(df_nested[df_nested['loss type']=='train'], values='loss', index='k', columns='lambda')\n",
    "pt_pl.fillna(value=pt_pl.loc[1,0.0], inplace=True)\n",
    "pt_linear.fillna(value=pt_linear.loc[1,0.0], inplace=True)\n",
    "pt_cdm.fillna(value=pt_cdm.loc[1,0.0], inplace=True)\n",
    "pt_nested.fillna(value=pt_nested.loc[1,0.0], inplace=True)\n",
    "sns.heatmap(pt_pl, annot=True, fmt='.2f', cmap=pl_palette, ax=ax[0,0]).set(title = 'Fixed effect', xlabel='')\n",
    "sns.heatmap(pt_linear, annot=True, fmt='.2f', cmap=linear_palette, ax=ax[0,1]).set(title = 'Linear', xlabel='', ylabel='')\n",
    "sns.heatmap(pt_cdm, annot=True, fmt='.2f', cmap=cdm_palette, ax=ax[0,2]).set(title = 'CDM', xlabel='', ylabel='')\n",
    "sns.heatmap(pt_nested, annot=True, fmt='.2f', cmap=nested_palette, ax=ax[0,3]).set(title = 'Nested', xlabel='', ylabel='')\n",
    "\n",
    "pt_pl = pd.pivot_table(df_pl[df_pl['loss type']=='val'], values='loss', index='k', columns='lambda')\n",
    "pt_linear = pd.pivot_table(df_linear[df_linear['loss type']=='val'], values='loss', index='k', columns='lambda')\n",
    "pt_cdm = pd.pivot_table(df_cdm[df_cdm['loss type']=='val'], values='loss', index='k', columns='lambda')\n",
    "pt_nested = pd.pivot_table(df_nested[df_nested['loss type']=='val'], values='loss', index='k', columns='lambda')\n",
    "pt_pl.fillna(value=pt_pl.loc[1,0.0], inplace=True)\n",
    "pt_linear.fillna(value=pt_linear.loc[1,0.0], inplace=True)\n",
    "pt_cdm.fillna(value=pt_cdm.loc[1,0.0], inplace=True)\n",
    "pt_nested.fillna(value=pt_nested.loc[1,0.0], inplace=True)\n",
    "sns.heatmap(pt_pl, annot=True, fmt='.3f', cmap=pl_palette, ax=ax[1,0]).set(xlabel=r'$\\lambda_\\mathcal{L}$')\n",
    "sns.heatmap(pt_linear, annot=True, fmt='.3f', cmap=linear_palette, ax=ax[1,1]).set(xlabel=r'$\\lambda_\\mathcal{L}$', ylabel='')\n",
    "sns.heatmap(pt_cdm, annot=True, fmt='.3f', cmap=cdm_palette, ax=ax[1,2]).set(xlabel=r'$\\lambda_\\mathcal{L}$', ylabel='')\n",
    "sns.heatmap(pt_nested, annot=True, fmt='.3f', cmap=nested_palette, ax=ax[1,3]).set(xlabel=r'$\\lambda_\\mathcal{L}$', ylabel='')\n",
    "fig.savefig('../Figs/strat_hyperparam_heatmaps.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load test attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_attributes_test = pd.read_csv(TEST_SCHOOL_ATTS_PATH, index_col='school_id')\n",
    "for column in ['ela_color', 'math_color', 'chronic_color', 'suspension_color']:\n",
    "    school_attributes_test[column].replace(['Red', 'Orange', 'Yellow', 'Green', 'Blue'], [1.,2.,3.,4.,5.], inplace=True)\n",
    "school_attributes_test['AvgColorIndex'] = school_attributes_test[['ela_color', 'math_color', 'chronic_color', 'suspension_color']].mean(numeric_only=True, axis=1)\n",
    "school_attributes_test['% FRL 2019-2022'] = detailed_school_attributes.loc[school_attributes_test.index,'% FRL']\n",
    "school_attributes_test['has_before_school_progs'] = detailed_school_attributes.loc[school_attributes_test.index,'Has Before School Programs'].map({'Yes':1, 'No':0})\n",
    "school_attributes_test['has_after_school_progs'] = detailed_school_attributes.loc[school_attributes_test.index,'Has After School Programs'].map({'Yes':1, 'No':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_attributes_test = pd.read_csv(TEST_PROGRAM_ATTS_PATH, index_col='program_id')\n",
    "program_attributes_test['school_id'] = program_attributes_test.school_id.astype(int)\n",
    "program_attributes_test['nest_membership'] = [prog_to_nest[program_type] for program_type in program_attributes_test['program_type']]\n",
    "program_attributes_test['AvgColorIndex'] = [school_attributes_test.loc[school,'AvgColorIndex'] for school in program_attributes_test.school_id]\n",
    "program_attributes_test['portion_FRL'] = [school_attributes_test.loc[school,'% FRL 2019-2022']/100. for school in program_attributes_test.school_id]\n",
    "program_attributes_test['has_before_school_progs'] = [school_attributes_test.loc[school,'has_before_school_progs'] for school in program_attributes_test.school_id]\n",
    "program_attributes_test['has_after_school_progs'] = [school_attributes_test.loc[school,'has_after_school_progs'] for school in program_attributes_test.school_id]\n",
    "program_attributes_test = pd.concat([program_attributes_test, program_attributes_train[~program_attributes_train.index.isin(program_attributes_test.index)]])\n",
    "program_attributes_test['nest_id'] = [nests.index(nest) for nest in program_attributes_test['nest_membership']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[(df.year==TEST_YEAR)&(df.first_participated_round==1)]\n",
    "dataset_test = dp.clean_dataframe(df_test, program_attributes_test, program_sqrt_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = generate_covariate_matrix(program_attributes_train, student_codex, program_codex, ctip_codex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(xtest, xltest, ytest), student_codex_test, ctip_codex_test = dp.prep_valset(dataset_test, program_attributes_test, program_codex)\n",
    "X_test = generate_covariate_matrix(program_attributes_test, student_codex_test, program_codex, ctip_codex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No. students: ', len(student_codex_test))\n",
    "print('No. programs: ', num_programs)\n",
    "print('Avg. len of ranking', dataset_test.num_ranked.mean())\n",
    "print('No. training examples', xtest.shape[0])\n",
    "print('% CTIP1', ctip_codex_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # forward, strat, num_ranks=5):\n",
    "def full_train_test(model_string, fe, linear, context, forward, strat, num_ranks=5):\n",
    "    result=[]\n",
    "    train = pd.concat(folds)\n",
    "\n",
    "    train_choices, train_st_codex, train_prog_codex, train_school_codex, train_program_to_school, train_program_type_codex, train_program_to_type, train_ctip_codex, train_ballot = dp.prep_dataset(train, program_attributes_train)\n",
    "    X_train = generate_covariate_matrix(program_attributes_train, train_st_codex, train_prog_codex, train_ctip_codex)\n",
    "    (xtest, xltest, ytest), test_st_codex, test_ctip_codex = dp.prep_valset(dataset_test, program_attributes_test, train_prog_codex)\n",
    "    X_test = generate_covariate_matrix(program_attributes_test, test_st_codex, train_prog_codex, test_ctip_codex)\n",
    "    \n",
    "    if model_string=='null':\n",
    "        tr_loss, tr_loss_terms = compute_null_loss(train_choices[0], train_choices[1], train_choices[2], num_ranks=num_ranks)\n",
    "        test_loss, test_loss_terms = compute_null_loss(xtest, xltest, ytest, num_ranks=num_ranks)\n",
    "        result.append([model_string, strat, forward, 'train', 'all', float(tr_loss), 0.0, 0.0])\n",
    "        result.append([model_string, strat, forward, 'test', 'all', float(test_loss), 0.0, 0.0])\n",
    "        for j in range(num_ranks):\n",
    "            result.append([model_string, strat, forward, 'train', j, float(tr_loss_terms[j]), 0.0, 0.0])\n",
    "            result.append([model_string, strat, forward, 'test', j, float(test_loss_terms[j]), 0.0, 0.0])\n",
    "        return ((model_string, None), result)\n",
    "    elif model_string in ['nested', 'strat nested']:\n",
    "        nest_memberships = program_attributes_test.loc[train_prog_codex,'nest_id'].values\n",
    "        kwargs={'item_to_school': train_program_to_school,\n",
    "                'item_to_program': train_program_to_type,\n",
    "                'covariates': X_train,\n",
    "                'num_nests': len(nests),\n",
    "                'nest_memberships': nest_memberships,\n",
    "                'k': 10 if strat else 1,\n",
    "                'lambda_reg': 1e-3 if strat else 0.0,\n",
    "                'num_ranks': num_ranks}\n",
    "        model, tr_loss, num_epochs, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                            num_items=len(train_prog_codex), \n",
    "                                                            epochs=1000, \n",
    "                                                            lr=1e-3, \n",
    "                                                            wd=1e-5, \n",
    "                                                            verbose=True, \n",
    "                                                            Model=sp.NestedMNL,\n",
    "                                                            **kwargs)\n",
    "        no_params = sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])    \n",
    "        tr_losses = np.array(tr_losses)\n",
    "        task_loss = tr_loss - tr_losses[-1, -1] if strat else tr_loss\n",
    "        result.append([model_string, strat, forward, 'train', 'all', float(task_loss), num_epochs, no_params])\n",
    "        result.append([model_string, strat, forward, 'train + reg', 'all', float(tr_loss), num_epochs, no_params])\n",
    "        \n",
    "        ytest_hat = model.forward(xtest, xltest, X_test)\n",
    "        test_loss, test_loss_terms = model.loss_func(ytest_hat, ytest, xltest, train=False)\n",
    "        result.append([model_string, strat, forward, 'test', 'all', float(test_loss), num_epochs, no_params])\n",
    "        for j in range(num_ranks):\n",
    "            result.append([model_string, strat, forward, 'train', j, float(tr_losses[-1, j]), num_epochs, no_params])\n",
    "            result.append([model_string, strat, forward, 'test', j, float(test_loss_terms[j]), num_epochs, no_params])\n",
    "        return ((model_string, model), result)\n",
    "    else:\n",
    "        kwargs={'fixed_effects': fe,\n",
    "                'item_to_school': train_program_to_school,\n",
    "                'item_to_program': train_program_to_type,\n",
    "                'linear_terms': linear,\n",
    "                'covariates': X_train,\n",
    "                'context': context,\n",
    "                'forward_dependent': forward,\n",
    "                'embedding_dim': 10,\n",
    "                'k': 10 if strat else 1,\n",
    "                'lambda_reg': 1e-3 if (model_string=='strat cdm') else 1e-4 if (model_string in ['strat linear', 'strat fixed']) else 0.0, \n",
    "                'num_ranks': num_ranks}\n",
    "        model, tr_loss, num_epochs, tr_losses, _ = sp.train(ds=train_choices, \n",
    "                                                            num_items=len(train_prog_codex), \n",
    "                                                            epochs=1000, \n",
    "                                                            lr=1e-3, \n",
    "                                                            wd=1e-5, \n",
    "                                                            verbose=True, \n",
    "                                                            **kwargs)\n",
    "        no_params = sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])    \n",
    "        tr_losses = np.array(tr_losses)\n",
    "        task_loss = tr_loss - tr_losses[-1, -1] if strat else tr_loss\n",
    "        result.append([model_string, strat, forward, 'train', 'all', float(task_loss), num_epochs, no_params])\n",
    "        result.append([model_string, strat, forward, 'train + reg', 'all', float(tr_loss), num_epochs, no_params])\n",
    "        \n",
    "        ytest_hat = model.forward(xtest, xltest, X_test)\n",
    "        test_loss, test_loss_terms = model.loss_func(ytest_hat, ytest, xltest, train=False)\n",
    "        result.append([model_string, strat, forward, 'test', 'all', float(test_loss), num_epochs, no_params])\n",
    "        for j in range(num_ranks):\n",
    "            result.append([model_string, strat, forward, 'train', j, float(tr_losses[-1, j]), num_epochs, no_params])\n",
    "            result.append([model_string, strat, forward, 'test', j, float(test_loss_terms[j]), num_epochs, no_params])\n",
    "        return ((model_string, model), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_names=['null', 'fixed', 'strat fixed', 'linear', 'strat linear', 'cdm', 'strat cdm', 'nested', 'strat nested']\n",
    "fixed_effects=[False, True, True, True, True, True, True, True, True]\n",
    "linears=[False, False, False, True, True, True, True, True, True]\n",
    "contexts=[False, False, False, False, False, True, True, False, False]\n",
    "strats=[False, False, True, False, True, False, True, False, True]\n",
    "full_train_results = Parallel(n_jobs=-4)(delayed(full_train_test)(model_string, fe, linear, context, False, strat) \n",
    "                                         for model_string, fe, linear, context, strat in zip(model_names, \n",
    "                                                                                             fixed_effects, \n",
    "                                                                                             linears, \n",
    "                                                                                             contexts,\n",
    "                                                                                             strats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dict = {model_tuple[0]: model_tuple[1] for model_tuple, _ in full_train_results}\n",
    "full_train_df = pd.DataFrame([subitem for _, result in full_train_results for subitem in result],\n",
    "                             columns=['model name', 'stratified', 'forward', 'loss type', 'rank', 'loss', 'num epochs', 'no params'])\n",
    "full_train_df['model'] = [name.split()[-1] for name in full_train_df['model name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Figures 3, 8, 9 & 10: Parameter estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figure 8: Stratified fixed-effects, $\\hat\\delta^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(25,6), gridspec_kw={'width_ratios': [2, 1]})\n",
    "pl_school_logits = pd.Series(model_dict['strat fixed'].school_logits[0].weight.detach().numpy()[:-1].flatten(), index=school_codex)\n",
    "pl_program_logits = pd.Series(model_dict['strat fixed'].program_logits[0].weight.detach().numpy()[:-1].flatten(), index=program_type_codex)\n",
    "sorted_schools = pl_school_logits.sort_values(ascending=False).index\n",
    "sorted_programs = pl_program_logits.sort_values(ascending=False).index\n",
    "\n",
    "strat_school_logits = [pd.Series(model_dict['strat fixed'].school_logits[i].weight.detach().numpy()[:-1].flatten(), index=school_codex) for i in range(model_dict['strat fixed'].k)]\n",
    "shifted_logits = [(logit - logit.mean()) for logit in strat_school_logits]\n",
    "strat_logits_df = pd.DataFrame(shifted_logits).T.melt(ignore_index=False).reset_index()\n",
    "strat_logits_df['bucket'] = strat_logits_df['variable'].map({i: '$k=$' + str(i+1) for i in range(10)})\n",
    "sns.barplot(data=strat_logits_df[strat_logits_df.bucket.isin(['$k=$1', '$k=$10'])], \n",
    "            x='index', y='value', hue='bucket', order=sorted_schools, \n",
    "            palette=sns.light_palette(palette[1],n_colors=3)[-2:], ax=ax[0]).set(xticklabels=[],\n",
    "                                                                                 xlabel='School',\n",
    "                                                                                 ylabel='Fixed-effect',\n",
    "                                                                                 title='Stratified school fixed-effect $\\hat\\delta_s^k$')\n",
    "\n",
    "strat_program_logits = [pd.Series(model_dict['strat fixed'].program_logits[i].weight.detach().numpy()[:-1].flatten(), index=program_type_codex) for i in range(model_dict['strat fixed'].k)]\n",
    "shifted_logits = [(logit - logit.mean()) for logit in strat_program_logits]\n",
    "strat_logits_df = pd.DataFrame(shifted_logits).T.melt(ignore_index=False).reset_index()\n",
    "strat_logits_df['bucket'] = strat_logits_df['variable'].map({i: '$k=$' + str(i+1) for i in range(10)})\n",
    "sns.barplot(data=strat_logits_df[strat_logits_df.bucket.isin(['$k=$1', '$k=$10'])], \n",
    "            x='index', y='value', hue='bucket', order=sorted_programs, \n",
    "            palette=sns.light_palette(palette[1],n_colors=3)[-2:], ax=ax[1]).set(xticklabels=[],\n",
    "                                                                                 xlabel='Program-type',\n",
    "                                                                                 ylabel='Fixed-effect',\n",
    "                                                                                 title='Stratified program-type fixed-effect $\\hat\\delta_p^k$')\n",
    "plt.legend()\n",
    "fig.savefig('../Figs/strat_logits.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figure 9: Non-stratified coefficients, $\\hat\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta_linear = pd.concat([pd.DataFrame([beta.weight.detach().numpy().flatten(), covariate_names, np.full((len(covariate_names)), fill_value=i+1)]).transpose() for i, beta in enumerate(model_dict['linear'].beta)])\n",
    "beta_linear.columns=['coefficient','covariate','k']\n",
    "beta_cdm = pd.concat([pd.DataFrame([beta.weight.detach().numpy().flatten(), covariate_names, np.full((len(covariate_names)), fill_value=i+1)]).transpose() for i, beta in enumerate(model_dict['cdm'].beta)])\n",
    "beta_cdm.columns=['coefficient','covariate','k']\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15,6), sharex=True, sharey=True)\n",
    "sns.barplot(data = beta_linear, x='covariate', y='coefficient', color=palette[2], ax=ax[0]).set(\n",
    "        title=r'Linear $\\hat{\\beta}$',\n",
    "        xlabel='',\n",
    "        ylabel=r'Coefficient'\n",
    "    )\n",
    "sns.barplot(data = beta_cdm, x='covariate', y='coefficient', color=palette[3], ax=ax[1]).set(\n",
    "        title=r'CDM $\\hat{\\beta}$',\n",
    "        xlabel='',\n",
    "        ylabel=r'Coefficient'\n",
    "    )\n",
    "ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=45, fontdict={'horizontalalignment':'right'})\n",
    "fig.savefig('../Figs/beta.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figure 10: Stratified coefficients, $\\hat\\beta^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta_linear = pd.concat([pd.DataFrame([beta.weight.detach().numpy().flatten(), covariate_names, np.full((len(covariate_names)), fill_value=i+1)]).transpose() for i, beta in enumerate(model_dict['strat linear'].beta)])\n",
    "beta_linear.columns=['coefficient','covariate','k']\n",
    "\n",
    "beta_cdm = pd.concat([pd.DataFrame([beta.weight.detach().numpy().flatten(), covariate_names, np.full((len(covariate_names)), fill_value=i+1)]).transpose() for i, beta in enumerate(model_dict['strat cdm'].beta)])\n",
    "beta_cdm.columns=['coefficient','covariate','k']\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(17,10), sharex=True)\n",
    "sns.barplot(data = beta_linear, x='covariate', y='coefficient', hue='k', palette = sns.light_palette(palette[2],n_colors=10)[::-1], ax=ax[0]).set(\n",
    "        title=r'Stratified Linear $\\hat{\\beta}$',\n",
    "        xlabel='',\n",
    "        ylabel=r'Coefficient'\n",
    "    )\n",
    "sns.barplot(data = beta_cdm, x='covariate', y='coefficient', hue='k', palette = sns.light_palette(palette[3],n_colors=10)[::-1], ax=ax[1]).set(\n",
    "        title=r'Stratified CDM $\\hat{\\beta}$',\n",
    "        xlabel='',\n",
    "        ylabel=r'Coefficient',\n",
    "    )\n",
    "ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=45, fontdict={'horizontalalignment': 'right'})\n",
    "ax[0].legend(bbox_to_anchor=(1.0, 1.02))\n",
    "ax[1].legend(bbox_to_anchor=(1.0, 1.02))\n",
    "fig.savefig('../Figs/strat_beta.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figure 3: Non-stratified CDM contexts, $\\hat U$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_school_logits = pd.Series(model_dict['fixed'].school_logits[0].weight.detach().numpy()[:-1].flatten(), index=school_codex)\n",
    "pl_program_logits = pd.Series(model_dict['fixed'].program_logits[0].weight.detach().numpy()[:-1].flatten(), index=program_type_codex)\n",
    "pl_logits = pl_school_logits.iloc[program_to_school].values + pl_program_logits.iloc[program_to_program_type].values\n",
    "pl_logits -= pl_logits.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_mapping = pd.DataFrame({\n",
    "    'program type': ['GE', \n",
    "                     'SN', 'SE', 'NS', 'SB',\n",
    "                     'MM', 'MS', 'SA', 'AF', 'ED', 'DA', 'DT',\n",
    "                     'CE', 'CN', 'ME', 'MN', 'CT', 'NC', 'CB', \n",
    "                     'JN', 'JE', 'JB', \n",
    "                     'KE', 'KN',\n",
    "                     'FB'],\n",
    "})\n",
    "sort_mapping = prog_mapping.reset_index().set_index('program type')\n",
    "program_attributes_train['program_num'] = program_attributes_train['program_type'].map(sort_mapping['index'])\n",
    "program_attributes_train['logits'] = 0.0\n",
    "program_attributes_train.loc[program_codex, 'logits'] = -pl_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = pd.DataFrame(model_dict['cdm'].target_embeddings[0].weight.detach().numpy()[:-1], index=program_codex)\n",
    "context = pd.DataFrame(model_dict['cdm'].context_embeddings[0].weight.detach().numpy()[:-1], index=program_codex)\n",
    "Ufull = target.values @ context.values.T\n",
    "np.fill_diagonal(Ufull,0); Ufull -= Ufull.sum()/(num_programs*(num_programs-1)); np.fill_diagonal(Ufull,0)\n",
    "\n",
    "Ufull_df = pd.DataFrame(Ufull, index=program_codex, columns=program_codex)\n",
    "sorted_U_df = Ufull_df.loc[program_attributes_train.loc[program_codex].sort_values(by=['program_num', 'logits']).index, \n",
    "                           program_attributes_train.loc[program_codex].sort_values(by=['program_num', 'logits']).index]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "sns.heatmap(data=sorted_U_df, cmap='RdBu', square=True, \n",
    "            xticklabels=False, yticklabels=False, \n",
    "            vmin=-17, vmax=17, ax=ax).set(xlabel='', ylabel='')\n",
    "\n",
    "program_bucket_sizes = list(program_attributes_train.loc[program_codex].sort_values(by=['program_num', 'logits']).nest_membership.value_counts().values[:4]) + [program_attributes_train.loc[program_codex].sort_values(by=['program_num', 'logits']).nest_membership.value_counts().values[4:].sum()]\n",
    "program_indices = [0]\n",
    "for value in program_bucket_sizes[:-1]:\n",
    "    program_indices.append(program_indices[-1]+value)\n",
    "rectangles = [plt.Rectangle((i,i), size, size, color=\"gray\", linewidth=1, fill=False, clip_on=False) \n",
    "              for i, size in zip(program_indices, program_bucket_sizes)]\n",
    "for rect in rectangles:\n",
    "    ax.add_patch(rect)\n",
    "fig.savefig('../Figs/U_col.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Figures 1, 2, 4, & 11: Loss evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figure 1: NLL Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['nested'].scale_parameter.weight, nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank_results = full_train_df[(full_train_df['rank']!='all') & (full_train_df['loss type']!='train + reg')]\n",
    "overall_results = full_train_df[(full_train_df['rank']=='all') & (full_train_df['loss type']!='train + reg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results[overall_results['loss type']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_lines_0 = [Line2D([0], [0], color=sns.light_palette(palette[0], n_colors=5)[3], linestyle='-', marker='X', lw=2),\n",
    "                  Line2D([0], [0], color=sns.light_palette(palette[0], n_colors=5)[-1], linestyle='-', marker='o', lw=2)]\n",
    "custom_lines_1 = [Line2D([0], [0], color=palette[0], linestyle='-', marker='o', lw=2),\n",
    "                  Line2D([0], [0], color=palette[1], linestyle='-', marker='o', lw=2),\n",
    "                  Line2D([0], [0], color=palette[1], linestyle='--', marker='o', lw=2),\n",
    "                  Line2D([0], [0], color=palette[2], linestyle='-', marker='o', lw=2),\n",
    "                  Line2D([0], [0], color=palette[2], linestyle='--', marker='o', lw=2),\n",
    "                  Line2D([0], [0], color=palette[4], linestyle='-', marker='o', lw=2),\n",
    "                  Line2D([0], [0], color=palette[4], linestyle='--', marker='o', lw=2),\n",
    "                  Line2D([0], [0], color=palette[3], linestyle='-', marker='o', lw=2),\n",
    "                  Line2D([0], [0], color=palette[3], linestyle='--', marker='o', lw=2)]\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,4.7),sharey=True)\n",
    "sns.scatterplot(data=overall_results[(overall_results['loss type']=='train')], x='model name', y='loss', \n",
    "                hue='model', marker='X', s=50, alpha=0.8, palette=palette, ax=ax[0])\n",
    "sns.scatterplot(data=overall_results[(overall_results['loss type']=='test')], x='model name', y='loss', \n",
    "                hue='model', marker='o', palette=palette, ax=ax[0])\n",
    "ytrain=np.array([overall_results[(overall_results['model name']==model)&\n",
    "                                 (overall_results['loss type']=='train')]['loss'].values for model in model_names]).flatten()\n",
    "ytest=np.array([overall_results[(overall_results['model name']==model)&\n",
    "                                (overall_results['loss type']=='test')]['loss'].values for model in model_names]).flatten()\n",
    "sns.lineplot(x=[1,2], y=[ytrain[1], ytrain[2]], color=sns.light_palette(palette[1], n_colors=5)[3], ax=ax[0])\n",
    "sns.lineplot(x=[1,2], y=[ytest[1], ytest[2]], color=palette[1], ax=ax[0])\n",
    "sns.lineplot(x=[3,4], y=[ytrain[3], ytrain[4]], color=sns.light_palette(palette[2], n_colors=5)[3], ax=ax[0])\n",
    "sns.lineplot(x=[3,4], y=[ytest[3], ytest[4]], color=palette[2], ax=ax[0])\n",
    "sns.lineplot(x=[5,6], y=[ytrain[5], ytrain[6]], color=sns.light_palette(palette[3], n_colors=5)[3], ax=ax[0])\n",
    "sns.lineplot(x=[5,6], y=[ytest[5], ytest[6]], color=palette[3], ax=ax[0])\n",
    "sns.lineplot(x=[7,8], y=[ytrain[7], ytrain[8]], color=sns.light_palette(palette[4], n_colors=5)[3], ax=ax[0])\n",
    "sns.lineplot(x=[7,8], y=[ytest[7], ytest[8]], color=palette[4], ax=ax[0])\n",
    "\n",
    "sns.lineplot(data=rank_results[(rank_results['loss type']=='test')], \n",
    "             x='rank', y='loss', hue='model', style='stratified', palette=palette, marker='o', ax=ax[1])\n",
    "\n",
    "ax[0].set_ylabel('NLL')\n",
    "ax[0].set_xlabel('Model')\n",
    "ax[0].tick_params(axis='x', labelrotation = 45)\n",
    "ax[0].set_xticklabels(['null', 'fixed', 'fixed, strat.', 'linear', 'linear, strat.', 'CDM', 'CDM, strat.', 'nested', 'nested, strat.'], fontdict={'horizontalalignment': 'right'})\n",
    "ax[0].legend(custom_lines_0, ['train (2017-18)', \n",
    "                              'test (2018-19)'])\n",
    "ax[1].set_xlabel(r'Position, $k$')\n",
    "ax[1].set_xticks([0,1,2,3,4])\n",
    "ax[1].set_xticklabels([1,2,3,4,5])\n",
    "ax[1].legend(custom_lines_1, ['null', \n",
    "                              'fixed', 'fixed, strat.', \n",
    "                              'linear', 'linear, strat.', \n",
    "                              'CDM', 'CDM, strat.', \n",
    "                              'nested', 'nested, strat.'], loc=(1.02, 0.35))\n",
    "fig.tight_layout()\n",
    "fig.savefig('../Figs/nll_losses.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figures 4 & 11: Comparison w/ Nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_student =  888006603\n",
    "sample_student_id = student_codex_test.index(888006603)\n",
    "top_choice = '420-MS-KG'\n",
    "top_choice_id = program_codex.index(top_choice)\n",
    "\n",
    "choice_set = list(np.arange(num_programs))\n",
    "choice_set.remove(top_choice_id)\n",
    "choice_set.append(num_programs)\n",
    "x1 = t.Tensor(np.vstack([np.arange(num_programs)[None,:], np.array(choice_set)[None,:]])).long()\n",
    "x2 = np.full((2,num_programs), fill_value=num_programs)\n",
    "x2[1,0] = top_choice_id\n",
    "x = t.Tensor(np.dstack([x1,x2])).long()\n",
    "x_extra = t.tensor([[sample_student_id, num_programs, 0],[sample_student_id, num_programs-1, 1]])\n",
    "likelihoods = np.exp(model_dict['linear'].forward(x, x_extra, X_test).detach().numpy()), np.exp(model_dict['nested'].forward(x, x_extra, X_test).detach().numpy()), np.exp(model_dict['cdm'].forward(x, x_extra, X_test).detach().numpy())\n",
    "for likelihood in likelihoods:\n",
    "    second_row = list(likelihood[1,:])\n",
    "    second_row.insert(top_choice_id, 0.0)\n",
    "    likelihood[1,:] = np.array(second_row[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df_list = []\n",
    "[probs_df_list.extend(zip([model]*likelihood.size, \n",
    "                          program_codex+program_codex, \n",
    "                          list(program_attributes_test.loc[program_codex, 'nest_membership'].values)+list(program_attributes_test.loc[program_codex, 'nest_membership'].values), \n",
    "                          ['top choice']*num_programs+['second choice']*num_programs, \n",
    "                          likelihood.flatten())) for model, likelihood in zip(['linear', 'nested', 'cdm'], likelihoods)]\n",
    "probs_df = pd.DataFrame(probs_df_list, columns=['Model', 'Program', 'Nest Membership', 'Position', 'Probability'])\n",
    "nest_order = ['Korean Language','Japanese Language','Filipino Language','Chinese Language','Spanish Language','General Education','Special Education']\n",
    "probs_df['Nest Membership'] = pd.Categorical(probs_df['Nest Membership'], nest_order)\n",
    "probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1,figsize=(20,12),sharey=True,sharex=True)\n",
    "sns.barplot(data = probs_df[(probs_df.Model=='linear')], x='Program', order=probs_df[(probs_df.Model=='linear')&(probs_df.Position=='top choice')].sort_values(by=['Nest Membership', 'Probability'], ascending=False).set_index('Program').index, \n",
    "            y='Probability', hue='Position', palette=sns.light_palette(palette[2], n_colors=5)[1:5:3], ax=ax[0])\n",
    "sns.barplot(data = probs_df[(probs_df.Model=='nested')], x='Program', order=probs_df[(probs_df.Model=='nested')&(probs_df.Position=='top choice')].sort_values(by=['Nest Membership', 'Probability'], ascending=False).set_index('Program').index, \n",
    "            y='Probability', hue='Position', palette=sns.light_palette(palette[-1], n_colors=5)[1:5:3], ax=ax[1])\n",
    "sns.barplot(data = probs_df[(probs_df.Model=='cdm')], x='Program', order=probs_df[(probs_df.Model=='cdm')&(probs_df.Position=='top choice')].sort_values(by=['Nest Membership', 'Probability'], ascending=False).set_index('Program').index,\n",
    "            y='Probability', hue='Position', palette=sns.light_palette(palette[3], n_colors=5)[1:5:3], ax=ax[2])\n",
    "nest_value_counts = probs_df[(probs_df.Model=='linear')&(probs_df.Position=='top choice')]['Nest Membership'].value_counts()\n",
    "for i in range(3):\n",
    "    ax[i].set_yscale('log')\n",
    "    # ax[i].set_ylim(1e-6,1.0)\n",
    "    ax[i].set_xlabel('')\n",
    "    ax[i].axvline(x=nest_value_counts.loc[nest_order[-1]]-0.5, color='k', linewidth=1)\n",
    "    ax[i].axvline(x=nest_value_counts.loc[nest_order[-2:]].sum()-0.5, color='k', linewidth=1)\n",
    "    ax[i].axvline(x=nest_value_counts.loc[nest_order[-3:]].sum()-0.5, color='k', linewidth=1)\n",
    "    ax[i].axvline(x=nest_value_counts.loc[nest_order[-4:]].sum()-0.5, color='k', linewidth=1)\n",
    "    ax[i].axvline(x=nest_value_counts.loc[nest_order[-5:]].sum()-0.5, color='k', linewidth=1)\n",
    "    ax[i].axvline(x=nest_value_counts.loc[nest_order[-6:]].sum()-0.5, color='k', linewidth=1)\n",
    "    ax[i].legend(loc='upper left', ncol=2)\n",
    "ax[0].set_title(r'Linear')\n",
    "ax[1].set_title(r'Nested')\n",
    "ax[2].set_title(r'CDM')\n",
    "ax[2].set_xticks(ticks = [nest_value_counts.loc[nest_order[-1]]//2, \n",
    "                          nest_value_counts.loc[nest_order[-1]]+nest_value_counts.loc[nest_order[-2]]//2, \n",
    "                          nest_value_counts.loc[nest_order[-2:]].sum()+nest_value_counts.loc[nest_order[-3]]//2,\n",
    "                          nest_value_counts.loc[nest_order[-3:]].sum()+nest_value_counts.loc[nest_order[-4]]//2,\n",
    "                          nest_value_counts.loc[nest_order[-4:]].sum()+nest_value_counts.loc[nest_order[-5]]//2,\n",
    "                          nest_value_counts.loc[nest_order[-5:]].sum()+nest_value_counts.loc[nest_order[-6]]//2,\n",
    "                          nest_value_counts.loc[nest_order[-6:]].sum()+nest_value_counts.loc[nest_order[-7]]//2],\n",
    "                labels = nest_order[::-1])\n",
    "ax[2].set_xlabel('Program')\n",
    "ax[2].set_xticklabels(ax[2].get_xticklabels(), rotation=45, fontdict={'horizontalalignment':'right'})\n",
    "plt.tight_layout()\n",
    "fig.savefig('../Figs/nested_probabilities.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1,figsize=(6,9),sharey=True,sharex=True)\n",
    "xaxis_order = probs_df[(probs_df.Model=='linear')&(probs_df.Position=='top choice')&(probs_df['Nest Membership']=='Special Education')].sort_values(by='Probability', ascending=False).set_index('Program').index\n",
    "sns.barplot(data = probs_df[(probs_df.Model=='linear')&(probs_df['Nest Membership']=='Special Education')], \n",
    "            x='Program', order=xaxis_order, y='Probability', hue='Position', \n",
    "            palette=sns.light_palette(palette[2], n_colors=5)[1:5:3], ax=ax[0])\n",
    "sns.barplot(data = probs_df[(probs_df.Model=='nested')&(probs_df['Nest Membership']=='Special Education')], \n",
    "            x='Program', order=xaxis_order, y='Probability', hue='Position', \n",
    "            palette=sns.light_palette(palette[-1], n_colors=5)[1:5:3], ax=ax[1])\n",
    "sns.barplot(data = probs_df[(probs_df.Model=='cdm')&(probs_df['Nest Membership']=='Special Education')], \n",
    "            x='Program', order=xaxis_order, y='Probability', hue='Position', \n",
    "            palette=sns.light_palette(palette[3], n_colors=5)[1:5:3], ax=ax[2])\n",
    "for i in range(3):\n",
    "    ax[i].set_yscale('log')\n",
    "    ax[i].set_ylim(1e-6,1.0)\n",
    "    ax[i].set_xlabel('')\n",
    "    ax[i].legend(loc='upper left', ncol=2)\n",
    "ax[0].set_title(r'Linear')\n",
    "ax[1].set_title(r'Nested')\n",
    "ax[2].set_title(r'CDM')\n",
    "ax[2].set_xlabel('Special Education Program')\n",
    "ax[2].set_xticklabels([])\n",
    "plt.tight_layout()\n",
    "fig.savefig('../Figs/nested_probabilities_speced.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figure 2: Top-K CDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_k_cdm(k, num_ranks=5):\n",
    "    result=[]    \n",
    "    train = pd.concat([df for df in folds])\n",
    "    \n",
    "    train_choices, train_st_codex, train_prog_codex, train_school_codex, train_program_to_school, train_program_type_codex, train_program_to_type, train_ctip_codex, train_ballot = dp.prep_dataset(train, program_attributes_train)\n",
    "    X_train = generate_covariate_matrix(program_attributes_train, train_st_codex, train_prog_codex, train_ctip_codex)\n",
    "    (xtest, xltest, ytest), test_st_codex, test_ctip_codex = dp.prep_valset(dataset_test, program_attributes_test, train_prog_codex)\n",
    "    X_test = generate_covariate_matrix(program_attributes_test, test_st_codex, train_prog_codex, test_ctip_codex)\n",
    "\n",
    "    kwargs={'fixed_effects': True,\n",
    "            'item_to_school': train_program_to_school,\n",
    "            'item_to_program': train_program_to_type,\n",
    "            'linear_terms': True,\n",
    "            'covariates': X_train,\n",
    "            'context': True,\n",
    "            'embedding_dim': 10,\n",
    "            'top_k': k,\n",
    "            'num_ranks': num_ranks}\n",
    "    model, tr_loss, num_epochs, tr_losses, _ = sp.train(ds=train_choices, num_items=len(train_prog_codex), epochs=1000, lr=1e-3, wd=1e-5, verbose=True, **kwargs)\n",
    "    no_params = sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])    \n",
    "    tr_losses = np.array(tr_losses)\n",
    "    result.append(['cdm', False, k, 'train', 'all', float(tr_loss), num_epochs, no_params])\n",
    "\n",
    "    ytest_hat = model.forward(xtest, xltest, X_test)\n",
    "    test_loss, test_loss_terms = model.loss_func(ytest_hat, ytest, xltest, train=False)\n",
    "    result.append(['cdm', False, k, 'test', 'all', float(test_loss), num_epochs, no_params])\n",
    "    for j in range(num_ranks):\n",
    "        result.append(['cdm', False, k, 'train', j, float(tr_losses[-1, j]), num_epochs, no_params])\n",
    "        result.append(['cdm', False, k, 'test', j, float(test_loss_terms[j]), num_epochs, no_params])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_k_cdm_results = Parallel(n_jobs=-4)(delayed(top_k_cdm)(k) for k in np.arange(num_programs)+1)\n",
    "top_k_cdm_df = pd.DataFrame([subitem for result in top_k_cdm_results for subitem in result], \n",
    "                             columns=['model name', 'stratified', 'k', 'loss type', 'rank', 'loss', 'num epochs', 'no params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_palette = [palette[3],sns.light_palette(palette[3], n_colors=5)[2]]\n",
    "custom_lines = [Line2D([0], [0], color=temp_palette[0], linestyle='', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=temp_palette[1], linestyle='', marker='X', lw=2)]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.scatterplot(data=overall_results[overall_results['model name']=='linear'], \n",
    "                x=0, y='loss', hue='loss type', style='loss type', palette=temp_palette, legend=False, ax=ax)\n",
    "sns.scatterplot(data=top_k_cdm_df[top_k_cdm_df['rank']=='all'], \n",
    "                x='k', y='loss', hue='loss type', style='loss type', palette=temp_palette, ax=ax)\n",
    "ax.set_ylabel('NLL')\n",
    "ax.set_xlabel(r'$k$')\n",
    "ax.legend(custom_lines, ['train (2017-18)', 'test (2018-19)'])\n",
    "ax.set_xticks([0,20,40,60,80,100,120,140, num_programs])\n",
    "ax.set_xticklabels([0,20,40,60,80,100,120,140,r'm'])\n",
    "fig.savefig('../Figs/top_k_cdm.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Figures 5 & 12: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figure 5: Accuracy at $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_DA_inputs(dataset, stud_codex, codex, program_data, compute_travel_times=False):\n",
    "    n=len(codex)\n",
    "    assert(dataset.shape[0]==len(stud_codex))\n",
    "    StudPrefs = np.full(fill_value=n, shape=(dataset.shape[0], n))\n",
    "    StudentPrts = np.zeros((dataset.shape[0], n))\n",
    "    for ind, row in dataset.iterrows():\n",
    "        student_id = int(row['student_id'])\n",
    "        programs = row['r1_ranked_programs'] if len(row['r1_ranked_programs'])!=0 else row['r2_ranked_programs'] if len(row['r2_ranked_programs'])!=0 else row['r3_ranked_programs'] if len(row['r3_ranked_programs'])!=0 else row['r4_ranked_programs'] if len(row['r4_ranked_programs'])!= 0 else row['r5_ranked_programs']\n",
    "        StudPrefs[student_id, :len(programs)] = [codex.index(program) for program in programs]\n",
    "        sibling, aaprek, aa = row['sibling'], row['aaprek'], row['idschoolattendance']\n",
    "        sib_programs, aaprek_programs = [], []\n",
    "        [sib_programs.extend(list(program_data[program_data.school_id==school].index.values)) for school in sibling]\n",
    "        index_sibling = [codex.index(program) for program in sib_programs if program in codex]\n",
    "        [aaprek_programs.extend(list(program_data[program_data.school_id==school].index.values)) for school in aaprek]\n",
    "        index_aaprek = [codex.index(program) for program in aaprek_programs if program in codex]\n",
    "        index_aa = [codex.index(program) for program in program_data[program_data.school_id==aa].index.values if program in codex]\n",
    "        '''\n",
    "        Encode priorities as follows:\n",
    "        Sibling  +16\n",
    "        AA Prek  +8\n",
    "        CTIP1    +4\n",
    "        AA       +2\n",
    "        Tiebreak +random number\n",
    "        '''\n",
    "        StudentPrts[student_id, index_sibling] += 16.\n",
    "        StudentPrts[student_id, index_aaprek] += 8.\n",
    "        if row['ctip1']:\n",
    "            StudentPrts[student_id] += 4.\n",
    "        StudentPrts[student_id, index_aa] += 2.\n",
    "    SchoolCaps = program_data.loc[codex, 'capacity'].values\n",
    "    return SchoolCaps, StudentPrts, StudPrefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['student_id']=[student_codex_test.index(studid) if studid in student_codex_test else None for studid in df_test['studentno']]\n",
    "subset_df_test = df_test.dropna(subset=['student_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SchoolCaps_test, StudentPrts_test, StudPrefs_test = generate_DA_inputs(subset_df_test, student_codex_test, program_codex, program_attributes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one(i, model_name, model, program_attributes, student_codex, \n",
    "                 program_codex, ctip_codex, prefs, rank, return_mode=False):\n",
    "    '''\n",
    "    Generates rank-position choice given prior rank choices in prefs.\n",
    "    '''\n",
    "    random.seed(model_name+str(i))\n",
    "    n_students = len(student_codex)\n",
    "    n_programs = len(program_codex)\n",
    "    \n",
    "    preferences = copy.deepcopy(prefs)\n",
    "    next_open_slot = np.argmax(preferences==n_programs, axis=1)\n",
    "    assert(max(next_open_slot)<=rank)\n",
    "    rows_to_sample = (next_open_slot==rank)\n",
    "    X_sample = generate_covariate_matrix(program_attributes, student_codex, program_codex, ctip_codex)\n",
    "    \n",
    "    if model_name=='null':\n",
    "        probs = np.divide(np.ones((n_students, n_programs+1)), (preferences==n_programs).sum(1)[:,None])\n",
    "        probs[np.arange(n_students)[:,None], preferences]=0.\n",
    "        preferences[rows_to_sample, rank] = probs[rows_to_sample,:].argmax(axis=1) if return_mode else t.multinomial(t.Tensor(probs)[rows_to_sample,:], num_samples=1).flatten()\n",
    "        return model_name, preferences\n",
    "    elif model_name in ['nested', 'strat nested']:\n",
    "        num_agents, num_alternatives, num_features = X_sample.shape\n",
    "        pad_mat = np.zeros((num_agents, num_features), dtype=np.float32)\n",
    "        X_sample = np.hstack([X_sample, pad_mat[:,None,:]]) # add zeros matrix to second dimension of covariates (column-wise)\n",
    "\n",
    "        X_sample = t.from_numpy(X_sample)\n",
    "        x = t.from_numpy(np.tile(np.arange(n_programs+1)[None,:], (n_students,1)))\n",
    "        x[np.arange(n_students)[:,None], preferences[:,:rank]] = n_programs\n",
    "        \n",
    "        x_extra = t.from_numpy(np.hstack((np.arange(n_students)[:,None], np.zeros((n_students,1)), next_open_slot[:,None]))).long()\n",
    "        C = t.ones((n_students, n_programs+1))\n",
    "        C[np.arange(n_students)[:,None], preferences[:,:rank]]=0.\n",
    "        probs = t.exp(model.compute_nested_logprobabilities(x[:,:-1], x_extra, C[:,:-1], X_sample, sampling=True))\n",
    "        probs = t.mul(probs,C[:,:-1])\n",
    "        if t.any(t.all(probs<=0., dim=1)):\n",
    "            print('Found all 0s row')\n",
    "            return\n",
    "        preferences[rows_to_sample,rank] = (probs[rows_to_sample]).argmax(axis=1).flatten() if return_mode else t.multinomial(probs[rows_to_sample],num_samples=1).flatten()\n",
    "        return model_name, preferences\n",
    "    else:\n",
    "        k=model.k\n",
    "        utilities = t.zeros((n_students, n_programs))\n",
    "        if model.fixed_effects:\n",
    "            utilities[rows_to_sample] += model.school_logits[min(k-1, rank)].weight.detach().numpy().flatten()[None,model.item_to_school[:-1]] + model.program_logits[min(k-1, rank)].weight.detach().numpy().flatten()[None, model.item_to_program_type[:-1]]\n",
    "        if model.linear_terms:\n",
    "            beta = model.beta[min(k-1, rank)].weight.detach().numpy().flatten()\n",
    "            utilities[rows_to_sample]+=X_sample[rows_to_sample]@beta #n_stud x n_prog\n",
    "        if (rank>0) & model.context:\n",
    "            T = model.target_embeddings[min(k-1, rank)].weight.detach().numpy()[:-1,:] # num_programs, embedding_dim\n",
    "            C = model.context_embeddings[min(k-1, rank)](preferences[rows_to_sample,:rank]).detach().numpy() # num_students, rank, embedding_dim\n",
    "            avg_C = C.mean(axis=-2) # num_students, embedding_dim\n",
    "            avg_interactions = (avg_C @ T.T)\n",
    "            utilities[rows_to_sample] += avg_interactions\n",
    "        utilities = np.concatenate((utilities, np.full((n_students, 1), fill_value=-np.inf)), axis=1)\n",
    "        utilities[np.arange(n_students)[:,None], preferences[:,:rank]]=-np.inf\n",
    "        viable_softmax_probs = softmax(utilities[rows_to_sample], axis=1)\n",
    "        preferences[rows_to_sample,rank] = viable_softmax_probs.argmax(axis=1) if return_mode else t.multinomial(t.Tensor(viable_softmax_probs), num_samples=1).flatten()\n",
    "        return model_name, preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples=100\n",
    "input_prefs = np.full((len(student_codex_test), num_programs), fill_value=num_programs)\n",
    "modal_results = {rank: [] for rank in range(10)}\n",
    "sample_results = {rank: [] for rank in range(10)}\n",
    "for rank in tqdm(range(10)):\n",
    "    input_prefs[:,:rank] = StudPrefs_test[:,:rank]\n",
    "    sample_results[rank]=Parallel(n_jobs=-4)(delayed(generate_one)(k, model_name, model_dict[model_name], program_attributes_test, student_codex_test, program_codex, \n",
    "                                                                  ctip_codex_test, input_prefs, rank) \n",
    "                                            for model_name in model_names\n",
    "                                            for k in range(num_samples))\n",
    "    modal_results[rank]=Parallel(n_jobs=-4)(delayed(generate_one)(0, model_name, model_dict[model_name], program_attributes_test, student_codex_test, program_codex, \n",
    "                                                                  ctip_codex_test, input_prefs, rank, return_mode=True)\n",
    "                                            for model_name in model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_modal = {i: {model: [] for model in model_names} for i in range(10)}\n",
    "results_sample = {i: {model: [] for model in model_names} for i in range(10)}\n",
    "for i in range(10):\n",
    "    [results_modal[i][name].append(pref) for name, pref in modal_results[i]]\n",
    "    [results_sample[i][name].append(pref) for name, pref in sample_results[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement(rank, model_name, array):\n",
    "    inds = (array[:, rank]!=num_programs) & (StudPrefs_test[:, rank]!=num_programs)\n",
    "    return rank, model_name, (array[inds,rank]==StudPrefs_test[inds,rank]).mean(), sum(inds)\n",
    "\n",
    "agreement_results=Parallel(n_jobs=-4)(delayed(agreement)(rank, model_name, array)\n",
    "                                        for rank in range(10) \n",
    "                                        for model_name in model_names \n",
    "                                        for array in results_modal[rank][model_name])\n",
    "modal_agreements=pd.DataFrame(agreement_results, columns=['rank position', 'model name', 'agreement w true', 'no. eligible ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modal_agreements[['model', 'stratified']] = [[name.split()[-1], 'strat' in name] for name in modal_agreements['model name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_lines = [Line2D([0], [0], color=palette[0], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[1], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[1], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[2], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[2], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[4], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[4], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[3], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[3], linestyle='--', marker='o', lw=2)]\n",
    "fig, ax=plt.subplots(1,1)\n",
    "sns.lineplot(data=modal_agreements, x='rank position', y='agreement w true', hue='model', style='stratified', palette=palette, marker='o', ax=ax)\n",
    "ax.set_xticks(np.arange(10), np.arange(10)+1)\n",
    "ax.legend(custom_lines, ['null', \n",
    "                         'fixed', 'fixed, strat.', \n",
    "                         'linear', 'linear, strat.',\n",
    "                         'nested', 'nested, strat.',\n",
    "                         'CDM', 'CDM, strat.'], loc='upper right', ncol=2)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel(r'Position, $k$')\n",
    "fig.savefig('../Figs/accuracy_at_k.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figure 12: By subpopulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexed_df = subset_df_test.set_index('studentno').loc[student_codex_test]\n",
    "reindexed_df['top_ranked_prog'] = 0\n",
    "for ind, row in reindexed_df.iterrows():\n",
    "    round_idx = row['first_participated_round']\n",
    "    programs = row['r'+str(round_idx)+'_programs']\n",
    "    reindexed_df.loc[ind, 'top_ranked_prog'] = programs[0]\n",
    "those_who_ranked_lang_first = reindexed_df['top_ranked_prog'].isin(program_to_language.keys())\n",
    "those_who_ranked_gened_first = reindexed_df['top_ranked_prog']=='GE'\n",
    "those_who_ranked_speced_first = ~(those_who_ranked_lang_first|those_who_ranked_gened_first)\n",
    "assert(all((those_who_ranked_lang_first|those_who_ranked_gened_first)|those_who_ranked_speced_first))\n",
    "those_with_siblings = (reindexed_df['sibling'].str.len()!=0).values\n",
    "those_with_aaprek = (reindexed_df['aaprek'].str.len()!=0).values\n",
    "those_with_aa = (~reindexed_df['idschoolattendance'].isna()).values\n",
    "print('AA:\\t\\t', those_with_aa.mean())\n",
    "print('Sibling:\\t', those_with_siblings.mean())\n",
    "print('CTIP1:\\t\\t', np.array(ctip_codex).mean())\n",
    "print('AAPrek:\\t\\t', those_with_aaprek.mean())\n",
    "print('Lang First:\\t', those_who_ranked_lang_first.mean())\n",
    "print('GenEd First:\\t', those_who_ranked_gened_first.mean())\n",
    "print('SpecEd First:\\t', those_who_ranked_speced_first.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement(rank, model_name, array, level='program', subpop=None, subset=None):\n",
    "    if subset is None:\n",
    "        subset=np.full(StudPrefs_test.shape[0], fill_value=True)\n",
    "    inds = subset & (array[:, rank]!=num_programs) & (StudPrefs_test[:, rank]!=num_programs)\n",
    "    if level=='program':\n",
    "        result = (array[inds,rank]==StudPrefs_test[inds,rank]).mean()\n",
    "    elif level=='school':\n",
    "        modal_programs = array[inds,rank]\n",
    "        modal_schools = program_attributes_test.loc[np.array(program_codex)[modal_programs], 'school_id']\n",
    "        true_programs = StudPrefs_test[inds,rank]\n",
    "        true_schools = program_attributes_test.loc[np.array(program_codex)[true_programs], 'school_id']\n",
    "        result = (modal_schools.values==true_schools.values).mean()\n",
    "    else:\n",
    "        return None\n",
    "    return rank, model_name, level, subpop, result, sum(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpop_agreement_results=Parallel(n_jobs=-4)(delayed(agreement)(rank, model_name, array, level, subpop, subset)\n",
    "                                             for model_name in model_names\n",
    "                                             for rank in [0,1,2]\n",
    "                                             for level in ['program', 'school']\n",
    "                                             for array in results_modal[rank][model_name]\n",
    "                                             for subpop, subset in [('AA', those_with_aa),\n",
    "                                                                    ('Sibling', those_with_siblings),\n",
    "                                                                    ('CTIP1', ctip_codex_test), \n",
    "                                                                    ('PreK/TK', those_with_aaprek),\n",
    "                                                                    ('Asian', (reindexed_df.resolved_ethnicity=='Asian').values),\n",
    "                                                                    ('Hisp./Latino', (reindexed_df.resolved_ethnicity=='Hispanic/Latino').values),\n",
    "                                                                    ('N/A', (reindexed_df.resolved_ethnicity=='Decline to State').values),\n",
    "                                                                    ('White', (reindexed_df.resolved_ethnicity=='White').values),\n",
    "                                                                    ('Two or More', (reindexed_df.resolved_ethnicity=='Two or More Races').values),\n",
    "                                                                    ('Black or A.A.', (reindexed_df.resolved_ethnicity=='Black or African American').values),\n",
    "                                                                    ('Gen. Ed.', those_who_ranked_gened_first),\n",
    "                                                                    ('Language', those_who_ranked_lang_first),\n",
    "                                                                    ('Spec. Ed.', those_who_ranked_speced_first)])\n",
    "subpop_modal_agreements = pd.DataFrame(subpop_agreement_results, columns=['rank position', 'model name', 'level', 'subpopulation', 'accuracy', 'no. eligible ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpop_modal_agreements[['model', 'stratified']] = [[name.split()[-1], 'strat' in name] for name in subpop_modal_agreements['model name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,sharey=True,figsize=(12,4))\n",
    "data = subpop_modal_agreements[(subpop_modal_agreements.model.isin(['linear', 'cdm', 'nested'])) & (subpop_modal_agreements.level=='program') & (subpop_modal_agreements.subpopulation.isin(['AA', 'Sibling', 'CTIP1', 'PreK/TK']))]\n",
    "sns.scatterplot(data=data[data['rank position']==0], x='subpopulation', y='accuracy', hue='model', style='stratified', palette=palette[2:], s=100, ax=ax[0])\n",
    "sns.scatterplot(data=data[data['rank position']==1], x='subpopulation', y='accuracy', hue='model', style='stratified', palette=palette[2:], s=100, ax=ax[1])\n",
    "sns.scatterplot(data=data[data['rank position']==2], x='subpopulation', y='accuracy', hue='model', style='stratified', palette=palette[2:], s=100, ax=ax[2])\n",
    "ax[0].set_title('Position 1')\n",
    "ax[1].set_title('Position 2')\n",
    "ax[2].set_title('Position 3')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "for i in range(3):\n",
    "    ax[i].legend().remove()\n",
    "    ax[i].set_xlabel('')\n",
    "    plt.setp(ax[i].get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", visible=True)\n",
    "custom_points = [Line2D([0], [0], marker='o', color=palette[2], lw=0), \n",
    "                 Line2D([0], [0], marker='x', color=palette[2], lw=0), \n",
    "                 Line2D([0], [0], marker='o', color=palette[3], lw=0), \n",
    "                 Line2D([0], [0], marker='x', color=palette[3], lw=0), \n",
    "                 Line2D([0], [0], marker='o', color=palette[4], lw=0), \n",
    "                 Line2D([0], [0], marker='x', color=palette[4], lw=0)]\n",
    "ax[2].legend(custom_points, ['linear', 'linear, strat.', 'CDM', 'CDM, strat.', 'nested', 'nested, strat.'])\n",
    "plt.tight_layout()\n",
    "fig.savefig('../Figs/by_subpopulation_priority.pdf', format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,sharey=True,figsize=(12,4.3))\n",
    "data = subpop_modal_agreements[(subpop_modal_agreements.model.isin(['linear', 'cdm', 'nested'])) & (subpop_modal_agreements.level=='program') & (subpop_modal_agreements.subpopulation.isin(['Asian', 'Hisp./Latino', 'N/A', 'White', 'Two or More', 'Black or A.A.']))]\n",
    "sns.scatterplot(data=data[data['rank position']==0], x='subpopulation', y='accuracy', hue='model', style='stratified', palette=palette[2:], s=100, ax=ax[0])\n",
    "sns.scatterplot(data=data[data['rank position']==1], x='subpopulation', y='accuracy', hue='model', style='stratified', palette=palette[2:], s=100, ax=ax[1])\n",
    "sns.scatterplot(data=data[data['rank position']==2], x='subpopulation', y='accuracy', hue='model', style='stratified', palette=palette[2:], s=100, ax=ax[2])\n",
    "ax[0].set_title('Position 1')\n",
    "ax[1].set_title('Position 2')\n",
    "ax[2].set_title('Position 3')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "for i in range(3):\n",
    "    ax[i].legend().remove()\n",
    "    ax[i].set_xlabel('')\n",
    "    plt.setp(ax[i].get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", visible=True)\n",
    "ax[2].legend(custom_points, ['linear', 'linear, strat.', 'CDM', 'CDM, strat.', 'nested', 'nested, strat.'])\n",
    "plt.tight_layout()\n",
    "fig.savefig('../Figs/by_subpopulation_demo.pdf', format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,sharey=True,figsize=(12,4))\n",
    "data = subpop_modal_agreements[(subpop_modal_agreements.model.isin(['linear', 'cdm', 'nested'])) & (subpop_modal_agreements.level=='program') & (subpop_modal_agreements.subpopulation.isin(['Gen. Ed.', 'Language', 'Spec. Ed.']))]\n",
    "sns.scatterplot(data=data[data['rank position']==0], x='subpopulation', y='accuracy', hue='model', style='stratified', palette=palette[2:], s=100, ax=ax[0])\n",
    "sns.scatterplot(data=data[data['rank position']==1], x='subpopulation', y='accuracy', hue='model', style='stratified', palette=palette[2:], s=100, ax=ax[1])\n",
    "sns.scatterplot(data=data[data['rank position']==2], x='subpopulation', y='accuracy', hue='model', style='stratified', palette=palette[2:], s=100, ax=ax[2])\n",
    "ax[0].set_title('Position 1')\n",
    "ax[1].set_title('Position 2')\n",
    "ax[2].set_title('Position 3')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "for i in range(3):\n",
    "    ax[i].legend().remove()\n",
    "    ax[i].set_xlabel('')\n",
    "    plt.setp(ax[i].get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", visible=True)\n",
    "ax[2].legend(custom_points, ['linear', 'linear, strat.', 'CDM', 'CDM, strat.', 'nested', 'nested, strat.'])\n",
    "plt.tight_layout()\n",
    "fig.savefig('../Figs/by_subpopulation_firstprog.pdf', format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Figure 13: Correlation & consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Kendall's $\\tau$ correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_preferences(i, model_name, model, program_attributes, student_codex, program_codex, ctip_codex, return_modal=False):\n",
    "    '''\n",
    "    Generates preferences that are either sampled from the distribution or the modal selection \n",
    "    (highest probability alternative) at each rank position.\n",
    "        - student_codex is in travel_times.index\n",
    "        - program_codex is same as used for training\n",
    "    '''\n",
    "    random.seed(model_name+str(i))\n",
    "    n_students = len(student_codex)\n",
    "    n_programs = len(program_codex)\n",
    "    preferences=t.zeros((n_students, n_programs),dtype=int)\n",
    "    X_sample = generate_covariate_matrix(program_attributes, student_codex, program_codex, ctip_codex)\n",
    "\n",
    "    if model is None:\n",
    "        probs=t.ones((n_students, n_programs))/float(n_programs)\n",
    "        preferences = t.multinomial(probs, num_samples=n_programs, replacement=False)\n",
    "        return model_name, preferences\n",
    "    \n",
    "    elif model_name in ['nested', 'strat nested']:\n",
    "        num_agents, num_alternatives, num_features = X_sample.shape\n",
    "        pad_mat = np.zeros((num_agents, num_features), dtype=np.float32)\n",
    "        X_sample = np.hstack([X_sample, pad_mat[:,None,:]]) # add zeros matrix to second dimension of covariates (column-wise)\n",
    "\n",
    "        X_sample = t.from_numpy(X_sample)\n",
    "        x = t.from_numpy(np.tile(np.arange(n_programs)[None,:], (n_students,1)))\n",
    "        x_extra = t.from_numpy(np.hstack((np.arange(n_students)[:,None], np.zeros((n_students,1)), np.zeros((n_students,1))))).long()\n",
    "        C = t.ones((n_students, n_programs))\n",
    "        for i in range(n_programs):\n",
    "            probs = t.exp(model.compute_nested_logprobabilities(x, x_extra, C, X_sample, sampling=True))\n",
    "            selections = t.multinomial(probs, num_samples=1).flatten()\n",
    "            preferences[:,i] = selections\n",
    "            x[np.arange(n_students), selections] = n_programs\n",
    "            C[np.arange(n_students), selections] = 0.\n",
    "            x_extra[:,2] = i+1\n",
    "        return model_name, preferences\n",
    "    \n",
    "    else:\n",
    "        for i in range(model.k-1):\n",
    "            utilities = t.zeros((n_students, n_programs))\n",
    "            if model.fixed_effects:\n",
    "                school_logits = model.school_logits[i].weight.detach().numpy().flatten()[model.item_to_school[:-1]]\n",
    "                program_logits = model.program_logits[i].weight.detach().numpy().flatten()[model.item_to_program_type[:-1]]\n",
    "                logits = school_logits + program_logits\n",
    "                utilities += logits[None,:]\n",
    "\n",
    "            if model.linear_terms:\n",
    "                linear = X_sample@model.beta[i].weight.detach().numpy().flatten()\n",
    "                utilities += linear\n",
    "\n",
    "            if (i>0) & model.context:\n",
    "                T = model.target_embeddings[i].weight.detach().numpy()[:-1,:] # num_programs, embedding_dim\n",
    "                C = model.context_embeddings[i](preferences[:,:i]).detach().numpy() # num_students, i, embedding_dim\n",
    "                avg_C = C.mean(axis=-2) # num_students, embedding_dim\n",
    "                avg_interactions = (avg_C @ T.T)\n",
    "                utilities += avg_interactions\n",
    "            utilities[np.arange(n_students)[:,None], preferences[:,:i]]=-np.inf\n",
    "            softmax_probs = softmax(utilities, axis=1)\n",
    "            preferences[:,i] = softmax_probs.argmax(1).flatten() if return_modal else t.multinomial(softmax_probs, num_samples=1).flatten()\n",
    "\n",
    "        utilities = t.zeros((n_students, n_programs))\n",
    "        if model.fixed_effects:\n",
    "            school_logits = model.school_logits[-1].weight.detach().numpy().flatten()[model.item_to_school[:-1]]\n",
    "            program_logits = model.program_logits[-1].weight.detach().numpy().flatten()[model.item_to_program_type[:-1]]\n",
    "            logits = school_logits + program_logits\n",
    "            utilities += logits[None,:]\n",
    "\n",
    "        if model.linear_terms:\n",
    "            linear = X_sample@model.beta[-1].weight.detach().numpy().flatten()\n",
    "            utilities += linear\n",
    "\n",
    "        if model.context:\n",
    "            T = model.target_embeddings[-1].weight.detach().numpy()[:-1,:] # num_programs, embedding_dim\n",
    "            for i in range(model.k-1,n_programs):\n",
    "                if i>0:\n",
    "                    C = model.context_embeddings[-1](preferences[:,:i]).detach().numpy() # num_students, i, embedding_dim\n",
    "                    avg_C = C.mean(axis=-2) # num_students, embedding_dim\n",
    "                    avg_interactions = (avg_C @ T.T)\n",
    "                    utilities += avg_interactions\n",
    "                utilities[np.arange(n_students)[:,None], preferences[:,:i]] = -np.inf\n",
    "                softmax_probs = softmax(utilities, axis=1)\n",
    "                preferences[:,i] = softmax_probs.argmax(1).flatten() if return_modal else t.multinomial(softmax_probs, num_samples=1).flatten()\n",
    "        else:\n",
    "            utilities[np.arange(n_students)[:,None], preferences[:,:(model.k-1)]] = -np.inf\n",
    "            softmax_probs = softmax(utilities, axis=1)\n",
    "            preferences[:,(model.k-1):] = (-softmax_probs).argsort(1)[:,:n_programs-(model.k-1)] if return_modal else t.multinomial(softmax_probs,num_samples=n_programs-(model.k-1),replacement=False)\n",
    "\n",
    "        return model_name, preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples=100\n",
    "sample_results = Parallel(n_jobs=-4)(delayed(generate_full_preferences)(i, \n",
    "                                                                        model_name, \n",
    "                                                                        model_dict[model_name],\n",
    "                                                                        program_attributes_test,\n",
    "                                                                        student_codex_test, \n",
    "                                                                        program_codex, \n",
    "                                                                        ctip_codex_test) \n",
    "                                     for i in range(num_samples) \n",
    "                                     for model_name in model_names)\n",
    "sampled_preferences = {key: [] for key in model_dict.keys()}\n",
    "for name, prefs in sample_results:\n",
    "    sampled_preferences[name].append(prefs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_sampled_prefs = {}\n",
    "for key, value in sampled_preferences.items():\n",
    "    stacked_sampled_prefs[key]=np.dstack(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_preferences_rank = {key: [array.argsort(axis=1) for array in sampled_preferences[key]] for key in model_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendall_tau_wrapper(model1, model2, array1, array2, num_rows):\n",
    "    rows_id = random.sample(range(array1.shape[0]), num_rows)\n",
    "    corr_list=[]\n",
    "    for row in rows_id:\n",
    "        corr_list.append(weightedtau(array1[row], array2[row])[0])\n",
    "    return model1, model2, corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_to_sample = 1000\n",
    "result = Parallel(n_jobs=-4)(delayed(kendall_tau_wrapper)(model1, model2, sampled_preferences_rank[model1][k], sampled_preferences_rank[model2][k+1], num_rows_to_sample)\n",
    "                             for model1, model2 in itertools.combinations_with_replacement(sampled_preferences_rank.keys(), r=2)\n",
    "                             for k in range(num_samples-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_kt_df = pd.DataFrame(0, index=['null', \n",
    "                         'fixed', 'strat fixed', \n",
    "                         'linear', 'strat linear',\n",
    "                         'nested', 'strat nested', \n",
    "                         'cdm', 'strat cdm'], columns=['null', \n",
    "                         'fixed', 'strat fixed', \n",
    "                         'linear', 'strat linear',\n",
    "                         'nested', 'strat nested', \n",
    "                         'cdm', 'strat cdm'])\n",
    "for model1, model2, corr_list in result:\n",
    "    total = np.array(corr_list).sum()\n",
    "    weighted_kt_df.loc[model2, model1] += total\n",
    "weighted_kt_matrix = (weighted_kt_df / (num_rows_to_sample * (num_samples-1))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(7,6))\n",
    "mask = np.zeros_like(weighted_kt_matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "np.fill_diagonal(mask, False)\n",
    "sns.heatmap(weighted_kt_matrix, \n",
    "            xticklabels=['null', \n",
    "                         'fixed', 'strat fixed', \n",
    "                         'linear', 'strat linear',\n",
    "                         'nested', 'strat nested', \n",
    "                         'CDM', 'strat CDM'], \n",
    "            yticklabels=['null', \n",
    "                         'fixed', 'strat fixed', \n",
    "                         'linear', 'strat linear',\n",
    "                         'nested', 'strat nested', \n",
    "                         'CDM', 'strat CDM'], \n",
    "            mask=mask, \n",
    "            square=True,\n",
    "            annot=True,\n",
    "            fmt='.2f', ax=ax)\n",
    "fig.savefig('../Figs/correlations.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Consistency at $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistency(rank, model_name, arr1, arr2):\n",
    "    inds = (arr1[:, rank]!=num_programs) & (arr2[:, rank]!=num_programs)\n",
    "    return rank, model_name, (arr1[inds,rank]==arr2[inds,rank]).mean(), sum(inds)\n",
    "consistency_results=Parallel(n_jobs=-4)(delayed(consistency)(rank, model_name, arr1, arr2)\n",
    "                                        for rank in range(10) \n",
    "                                        for model_name in model_names\n",
    "                                        for arr1, arr2 in itertools.combinations(results_sample[rank][model_name], r=2))\n",
    "consistencies=pd.DataFrame(consistency_results, columns=['rank position', 'model name', 'consistency', 'no. eligible ballots'])\n",
    "consistencies[['model', 'stratified']] = [[name.split()[-1], 'strat' in name] for name in consistencies['model name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_lines = [Line2D([0], [0], color=palette[0], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[1], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[1], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[2], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[2], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[4], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[4], linestyle='--', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[3], linestyle='-', marker='o', lw=2),\n",
    "                Line2D([0], [0], color=palette[3], linestyle='--', marker='o', lw=2)]\n",
    "fig, ax=plt.subplots(1,1)\n",
    "sns.lineplot(data=consistencies, x='rank position', y='consistency', hue='model', style='stratified', \n",
    "             palette=palette, marker='o', ax=ax)\n",
    "ax.set_xticks(np.arange(10), np.arange(10)+1)\n",
    "ax.set_ylabel('Consistency')\n",
    "ax.set_xlabel(r'Position, $k$')\n",
    "ax.legend(custom_lines, ['null', \n",
    "                         'fixed', 'fixed, strat.', \n",
    "                         'linear', 'linear, strat.', \n",
    "                         'nested', 'nested, strat.',\n",
    "                         'CDM', 'CDM, strat.'], loc='upper right', ncol=2)\n",
    "fig.savefig('../Figs/consistencies.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
